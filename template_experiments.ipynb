{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction Types\n",
    "<p> We have four templates to prompt the language model for sentiment analsis:\n",
    "<ol>\n",
    "  <li><b>No Template</b><br><br>\n",
    "  This is where we just feed the input sentence without changing any input format.<br>\n",
    "  Example: <br>\n",
    "  - <b>Sentence:</b><br>\n",
    "  'I hate watching this movie.'<br>\n",
    "  - <b>Input to the model:</b><br>\n",
    "  'I hate watching this movie.'\n",
    "  </li>\n",
    "  <br>\n",
    "\n",
    "  <li><b>Task Description</b><br><br>\n",
    "  We include a task description as an instruction before the actual sentence.\n",
    "  <br>\n",
    "  Example for binary sentiment classification: <br>\n",
    "  - <b>Sentence:</b><br>\n",
    "  'I hate watching this movie.'<br>\n",
    "  - <b>Input to the model:</b><br>\n",
    "  'Generate the sentiment of the next sentence from the labels positive, negative. I hate watching this movie.'\n",
    "  </li><br>\n",
    "\n",
    "  <li><b>Instruction Suffix</b><br><br>\n",
    "  We include a template at the end of the sentence for the sentiment classification task.\n",
    "  <br>\n",
    "  Example for binary sentiment classification: <br>\n",
    "  - <b>Sentence:</b><br>\n",
    "  'I hate watching this movie.'<br>\n",
    "  - <b>Input to the model:</b><br>\n",
    "  'I hate watching this movie. The sentiment of the previous sentence is'\n",
    "  </li><br>\n",
    "\n",
    "  <li><b>Questin-Answering Format</b><br><br>\n",
    "  We know this knowledge that the underlying T5 models are also pre-trained on QA datasets with a specific QA format. We will transfer sentiment classification to a generative QA task.\n",
    "  <br>\n",
    "  Example for binary sentiment classification: <br>\n",
    "  - <b>Sentence:</b><br>\n",
    "  'I hate watching this movie.'<br>\n",
    "  - <b>Input to the model:</b><br>\n",
    "  'question: what would be the sentiment of the sentence? context: I hate watching this movie.'\n",
    "  </li><br>\n",
    "</ol>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname: gpu041\r\n",
      "Node Rank 0\r\n",
      "Using Python from: /ssd003/home/snajafi/codes/PromptEngineering/prompt_torch-env/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "# define the internal cuda variables for gpu node in the vector's cluster.\n",
    "!source ./src/reference_implementations/setup_gpu_worker.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 on SemEval Sentiment\n",
    "\n",
    "In the first Experiment, we are going to make predictions on the semeval 3-way sentiment classification task without any prompt templates added to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p \"/tmp/template_experiments\"\n",
    "!mkdir -p \"/tmp/template_experiments/semeval\"\n",
    "!mkdir -p \"/tmp/template_experiments/semeval/experiment1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run our prediction script with the required arguments for the no template experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m src.reference_implementations.prompt_zoo.trainer \\\n",
    "    --batch_size 16 \\\n",
    "    --task_name semeval \\\n",
    "    --t5_exp_type no_finetune \\\n",
    "    --source_max_length 256 \\\n",
    "    --decoder_max_length 16 \\\n",
    "    --test_file ./resources/datasets/2018-Valence-oc-En-dev.txt \\\n",
    "    --model_path /tmp/template_experiments/semeval/experiment1 \\\n",
    "    --prediction_file /tmp/template_experiments/semeval/experiment1/semeval.predictions.csv \\\n",
    "    --with_instructions no_instruction \\\n",
    "    --t5_pretrained_model google/t5-large-lm-adapt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
