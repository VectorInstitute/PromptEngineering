{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Description\n",
    "\n",
    "<p> As a finetuning experiment, we are going to experiment with the following baselines including soft-prompt tuning. </p>\n",
    "<ul>\n",
    "\n",
    "  <li><b>All-finetuning</b>: We update every parameter in the encoder-decoder T5 on the downstream task. For this baseline a very small learning rate such as 0.0005 is effective.\n",
    "  </li></br>\n",
    "\n",
    "  <li><b>output-finetuning</b>: We update only the language modelling head on top of the T5 decoder on the downstream task. For this baseline a learning rate such as 0.001 is effective.\n",
    "  </li></br>\n",
    "\n",
    "  <li><b>input-finetuning</b>: We update only input embedding table for the T5 encoder on the downstream task. For this baseline a learning rate such as 0.001 is effective.\n",
    "  </li></br>\n",
    "\n",
    "  <li><b>classifier-finetuning</b>: We update only feedforward classifier which is built on the top of the T5 encoder on the downstream task. For this baseline a learning rate such as 0.001 is effective.\n",
    "  </li></br>\n",
    "\n",
    "  <li><b>soft-prompt tuning</b>: We update only prompt table included in the encoder-decoder T5 on the downstream task. \n",
    "  For soft-prompt tuning, a large learning rate around 0.3 is effective. In the experiments, we use 100 prompt tokens. Therefore our prompt length is 100.\n",
    "  </li></br>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<b>We are training these baselines on the semeval-2018 sentiment dataset for up to 30 epochs. We will use the vector's GPU cluster and the slurm scheduler to submit four GPU jobs to train these models. For this experiment, we don't need to login to a specific GPU node and we can submit the jobs from the login nodes on the vector vaughan cluster.</b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting the Training Jobs on SemEval Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submitting the job for all_finetuning baseline with the learning rate 0.0005\n",
    "!mkdir -p /scratch/ssd004/scratch/snajafi/data_temp/torch-prompt/semval\n",
    "!mkdir -p /scratch/ssd004/scratch/snajafi/data_temp/torch-prompt/semval/all_finetune\n",
    "\n",
    "!sbatch src/reference_implementations/run_singlenode_prompt.slrm \\\n",
    "    src/reference_implementations/prompt_zoo/finetuning_sentiment.sh \\\n",
    "    ./torch-prompt-tuning-exps-logs \\\n",
    "    all_finetune \\\n",
    "    semeval \\\n",
    "    /scratch/ssd004/scratch/snajafi/data_temp/torch-prompt/semval/all_finetune \\\n",
    "    0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submitting the job for input_finetuning baseline with the learning rate 0.001\n",
    "!mkdir -p /scratch/ssd004/scratch/snajafi/data_temp/torch-prompt/semval\n",
    "!mkdir -p /scratch/ssd004/scratch/snajafi/data_temp/torch-prompt/semval/input_finetune\n",
    "\n",
    "!sbatch src/reference_implementations/run_singlenode_prompt.slrm \\\n",
    "    src/reference_implementations/prompt_zoo/finetuning_sentiment.sh \\\n",
    "    ./torch-prompt-tuning-exps-logs \\\n",
    "    input_finetune \\\n",
    "    semeval \\\n",
    "    /scratch/ssd004/scratch/snajafi/data_temp/torch-prompt/semval/input_finetune \\\n",
    "    0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submitting the job for output_finetuning baseline with the learning rate 0.001\n",
    "!mkdir -p /scratch/ssd004/scratch/snajafi/data_temp/torch-prompt/semval\n",
    "!mkdir -p /scratch/ssd004/scratch/snajafi/data_temp/torch-prompt/semval/output_finetune\n",
    "\n",
    "!sbatch src/reference_implementations/run_singlenode_prompt.slrm \\\n",
    "    src/reference_implementations/prompt_zoo/finetuning_sentiment.sh \\\n",
    "    ./torch-prompt-tuning-exps-logs \\\n",
    "    output_finetune \\\n",
    "    semeval \\\n",
    "    /scratch/ssd004/scratch/snajafi/data_temp/torch-prompt/semval/output_finetune \\\n",
    "    0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submitting the job for classifier finetuning baseline with the learning rate 0.001\n",
    "!mkdir -p /scratch/ssd004/scratch/snajafi/data_temp/torch-prompt/semval\n",
    "!mkdir -p /scratch/ssd004/scratch/snajafi/data_temp/torch-prompt/semval/classifier_finetuning\n",
    "\n",
    "!sbatch src/reference_implementations/run_singlenode_prompt.slrm \\\n",
    "    src/reference_implementations/prompt_zoo/finetuning_sentiment.sh \\\n",
    "    ./torch-prompt-tuning-exps-logs \\\n",
    "    classifier_finetuning \\\n",
    "    semeval \\\n",
    "    /scratch/ssd004/scratch/snajafi/data_temp/torch-prompt/semval/classifier_finetuning \\\n",
    "    0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submitting the job for soft prompt tuning with the learning rate 0.3\n",
    "!mkdir -p /scratch/ssd004/scratch/snajafi/data_temp/torch-prompt/semval\n",
    "!mkdir -p /scratch/ssd004/scratch/snajafi/data_temp/torch-prompt/semval/soft_prompt_finetune\n",
    "\n",
    "!sbatch src/reference_implementations/run_singlenode_prompt.slrm \\\n",
    "    src/reference_implementations/prompt_zoo/soft_prompt_sentiment.sh \\\n",
    "    ./torch-prompt-tuning-exps-logs \\\n",
    "    soft_prompt_finetune \\\n",
    "    semeval \\\n",
    "    /scratch/ssd004/scratch/snajafi/data_temp/torch-prompt/semval/soft_prompt_finetune \\\n",
    "    0.3 \\\n",
    "    100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running hyper-parameter search and training of fine-tuning baselines on SST2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source prompt_torch-env/bin/activate\n",
    "!bash ./train_scripts/run_sst2_sentiment_experiments.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
