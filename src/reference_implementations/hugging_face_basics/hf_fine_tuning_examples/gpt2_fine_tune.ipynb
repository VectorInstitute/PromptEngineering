{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from custom_dataloaders import construct_dataloaders\n",
    "from gpt2_classification_model import Gpt2ClsModel\n",
    "from hf_trainer import infer, train\n",
    "from torch import cuda\n",
    "from transformers import GPT2Config, GPT2ForSequenceClassification, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/h/demerson/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4a69a04c9143298aca6f4fa991d7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /h/demerson/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-f9d9def1ebac2526.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data example encoding: tensor([12468,   263, 29651,  ..., 50256, 50256, 50256])\n",
      "Training data example decoding: Worker morale may take toll on airlines It is a management truism that low morale among workers inevitably results in low productivity, low quality, erosion of customer loyalty and, ultimately, lower profits.\n"
     ]
    }
   ],
   "source": [
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "# Define PAD Token = EOS Token = 50256\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "pad_token_id = gpt2_tokenizer.encode(gpt2_tokenizer.eos_token)[0]\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = construct_dataloaders(\n",
    "    batch_size=4, train_split_ratio=0.8, tokenizer=gpt2_tokenizer, dataset_name=\"ag_news\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the different variables we'd like for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "print(f\"Detected Device {device}\")\n",
    "# We'll provide two options. First we create our own model on top of the vanilla RoBERTa model. The second is to use\n",
    "# HuggingFace's GPT2ForSequenceClassification class, which essentially does the same thing.\n",
    "use_hf_sequence_classification = True\n",
    "gpt2_model_config = GPT2Config.from_pretrained(pretrained_model_name_or_path=\"gpt2\", num_labels=4)\n",
    "# The pad_token_id is used to determine when a sequence of inputs ends.\n",
    "gpt2_model_config.pad_token_id = pad_token_id\n",
    "gpt2_classifier_model = (\n",
    "    GPT2ForSequenceClassification.from_pretrained(\"gpt2\", config=gpt2_model_config)\n",
    "    if use_hf_sequence_classification\n",
    "    else Gpt2ClsModel(pad_token_id=pad_token_id)\n",
    ")\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "n_training_epochs = 1\n",
    "n_training_steps = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Model Training...\n",
      "Starting Epoch 0\n",
      "Completed batch number: 100 of 24000 in loader\n",
      "Training Loss over last 100 steps: 1.6661197769641876\n",
      "Training Accuracy over last 100 steps: 36.633663366336634%\n",
      "Validation Loss: 1.1145606362352185\n",
      "Validation Accuracy: 50.0%\n",
      "Completed batch number: 200 of 24000 in loader\n",
      "Training Loss over last 100 steps: 0.9291619142889976\n",
      "Training Accuracy over last 100 steps: 61.5%\n",
      "Validation Loss: 0.7292167333995595\n",
      "Validation Accuracy: 71.07843137254902%\n",
      "Completed batch number: 300 of 24000 in loader\n",
      "Training Loss over last 100 steps: 0.5718618040159344\n",
      "Training Accuracy over last 100 steps: 78.5%\n",
      "Validation Loss: 0.474610919717188\n",
      "Validation Accuracy: 85.7843137254902%\n",
      "Training rounds complete. Validating on entire validation set.\n",
      "Completed 300 of 6000...\n",
      "Completed 600 of 6000...\n",
      "Completed 900 of 6000...\n",
      "Completed 1200 of 6000...\n",
      "Completed 1500 of 6000...\n",
      "Completed 1800 of 6000...\n",
      "Completed 2100 of 6000...\n",
      "Completed 2400 of 6000...\n",
      "Completed 2700 of 6000...\n",
      "Completed 3000 of 6000...\n",
      "Completed 3300 of 6000...\n",
      "Completed 3600 of 6000...\n",
      "Completed 3900 of 6000...\n",
      "Completed 4200 of 6000...\n",
      "Completed 4500 of 6000...\n",
      "Completed 4800 of 6000...\n",
      "Completed 5100 of 6000...\n",
      "Completed 5400 of 6000...\n",
      "Completed 5700 of 6000...\n",
      "Completed 6000 of 6000...\n",
      "------------------------------------------------\n",
      "Training Loss Epoch: 1.052207141285422\n",
      "Validation Loss: 0.5340849707484012\n",
      "Validation accuracy: 81.08333333333333\n",
      "------------------------------------------------\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin Model Training...\")\n",
    "train(\n",
    "    gpt2_classifier_model, train_dataloader, val_dataloader, loss_function, device, n_training_epochs, n_training_steps\n",
    ")\n",
    "print(\"Training Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the final model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving model...\")\n",
    "output_model_file = \"./gpt2_ag_news.bin\"\n",
    "torch.save(gpt2_classifier_model, output_model_file)\n",
    "print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model back up and perform inference on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded.\n",
      "Evaluating model on test set...\n",
      "Completed 300 of 1900...\n",
      "Completed 600 of 1900...\n",
      "Completed 900 of 1900...\n",
      "Completed 1200 of 1900...\n",
      "Completed 1500 of 1900...\n",
      "Completed 1800 of 1900...\n",
      "Test Loss: 0.5428967128377898\n",
      "Test Accuracy: 80.67105263157895%\n",
      "Model evaluated.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model...\")\n",
    "gpt2_classifier_model = torch.load(output_model_file)\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_accuracy, test_loss = infer(gpt2_classifier_model, loss_function, test_dataloader, device)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}%\")\n",
    "print(\"Model evaluated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt_engineering",
   "language": "python",
   "name": "prompt_engineering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
