{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from pprint import pprint\n",
    "from typing import List\n",
    "\n",
    "import datasets\n",
    "import lingua\n",
    "from datasets import Dataset\n",
    "from lingua import Model\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a client connection to the Lingua service\n",
    "client = lingua.Client(gateway_host=\"llm.cluster.local\", gateway_port=3001)\n",
    "client.model_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.load_model(\"OPT-175B\")\n",
    "# If this model is not actively running, it will get launched in the background.\n",
    "# In this case, wait until it moves into an \"ACTIVE\" state before proceeding.\n",
    "while model.state != \"ACTIVE\":\n",
    "    time.sleep(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to configure the model to generate in the way we want it to. However, because we only care about the activations of our input, the configuration is less important. We need one but the parameters don't really matter. If you're curious about the values, please see other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_generation_config = {\"max_tokens\": 1, \"top_k\": 4, \"top_p\": 3, \"rep_penalty\": 1.0, \"temperature\": 1.0}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Generation \n",
    "\n",
    "Activation generation is quite easy. We can use the client to query the remote model and explore the various modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.module_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select the module names of interest and pass them into a `get_activations` function alongside our set of prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"Hello World\", \"Fizz Buzz\"]\n",
    "\n",
    "module_name = \"decoder.layers.11.fc2\"\n",
    "\n",
    "activations = model.get_activations(prompts, [module_name], short_generation_config)\n",
    "pprint(activations)\n",
    "\n",
    "# We sent a batch of 2 prompts to the model. So there is a list of length two activations returned\n",
    "for activations_single_prompt in activations.activations:\n",
    "    # For each prompt we extract the activations and calculate which label had the high likelihood.\n",
    "    raw_activations = activations_single_prompt[module_name]\n",
    "    # Note: Both prompts have two tokens.\n",
    "    # The activations should have shape (number of tokens = 2) x (activation size = 768)\n",
    "    print(\"Tensor Shape:\", raw_activations.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a proof of concept of the few-shot abilities of LLMs, we\"ll only use a small training dataset and will only perform validation using a small test subset for compute efficiency.\n",
    "\n",
    "* Training set: 100 randomly sampled training examples\n",
    "* Test set: 300 randomly sample test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = datasets.load_dataset(\"imdb\")\n",
    "train_size = 100\n",
    "test_size = 300\n",
    "n_demonstrations = 5\n",
    "\n",
    "activation_save_path = \"./resources/\"\n",
    "\n",
    "small_train_dataset = imdb[\"train\"].shuffle(seed=42).select([i for i in list(range(train_size))])\n",
    "small_test_dataset = imdb[\"test\"].shuffle(seed=42).select([i for i in list(range(test_size))])\n",
    "# We're going to be experimenting with the affect that prompting the model for the task we envision affects the\n",
    "# classifiers downstream performance. So we construct demonstrations here.\n",
    "small_demonstration_set = imdb[\"train\"].shuffle(seed=42).select([i for i in list(range(n_demonstrations))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher(seq: Dataset, size: int) -> Dataset:\n",
    "    return (seq[pos : pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\"s start by getting the activations associated with the raw review text. We\"ll do activations for the text coupled with a prompt below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_activations(\n",
    "    split: str, dataset: Dataset, model: Model, module_name: str, batch_size: int = 16\n",
    ") -> None:\n",
    "    print(\"Generating Activations: \" + split)\n",
    "\n",
    "    activations = []\n",
    "    for batch in tqdm(batcher(dataset, batch_size), total=int(len(dataset) / batch_size)):\n",
    "        prompts = batch[\"text\"]\n",
    "        activations.append(model.get_activations(prompts, [module_name], short_generation_config))\n",
    "\n",
    "    parsed_activations = []\n",
    "    for batch in activations:\n",
    "        for prompt_activation in batch:\n",
    "            parsed_activations.append(prompt_activation.activations[module_name])\n",
    "\n",
    "    cached_activations = {\"activations\": parsed_activations, \"labels\": dataset[\"label\"]}\n",
    "\n",
    "    with open(os.path.join(activation_save_path, f\"{split}_activations_demo.pkl\"), \"wb\") as handle:\n",
    "        pickle.dump(cached_activations, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_name = \"decoder.layers.11.fc2\"\n",
    "generate_dataset_activations(\"train\", small_train_dataset, model, module_name)\n",
    "generate_dataset_activations(\"test\", small_test_dataset, model, module_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let\"s generate activations pre-conditioned with an instruction and a few demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_demonstrations(instruction: str, demonstration_set: Dataset) -> str:\n",
    "    label_int_to_str = {0: \"negative\", 1: \"positive\"}\n",
    "    demonstration = f\"{instruction}\"\n",
    "    demo_texts = demonstration_set[\"text\"]\n",
    "    demo_labels = demonstration_set[\"label\"]\n",
    "    for text, label in zip(demo_texts, demo_labels):\n",
    "        demonstration = f\"{demonstration}\\n\\nText: {text} The sentiment is {label_int_to_str[label]}.\"\n",
    "    return f\"{demonstration}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompts(texts: List[str], demonstration: str) -> List[str]:\n",
    "    return [f\"{demonstration}{text} The sentiment is\" for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_activations_with_prompts(\n",
    "    split: str, demonstration: str, dataset: Dataset, model: Model, module_name: str, batch_size: int = 16\n",
    ") -> None:\n",
    "    print(\"Generating Activations with Prompts: \" + split)\n",
    "\n",
    "    activations = []\n",
    "    for batch in tqdm(batcher(dataset, batch_size), total=int(len(dataset) / batch_size)):\n",
    "        prompts = batch[\"text\"]\n",
    "        prompts = create_prompts(prompts, demonstration)\n",
    "        activations.append(model.get_activations(prompts, [module_name], short_generation_config))\n",
    "\n",
    "    parsed_activations = []\n",
    "    for batch in activations:\n",
    "        for prompt_activation in batch:\n",
    "            parsed_activations.append(prompt_activation.activations[module_name])\n",
    "\n",
    "    cached_activations = {\"activations\": parsed_activations, \"labels\": dataset[\"label\"]}\n",
    "\n",
    "    with open(os.path.join(activation_save_path, f\"{split}_activations_with_prompts_demo.pkl\"), \"wb\") as handle:\n",
    "        pickle.dump(cached_activations, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstration = create_demonstrations(\"Classify the sentiment of the text.\", small_demonstration_set)\n",
    "module_name = \"decoder.layers.11.fc2\"\n",
    "generate_dataset_activations_with_prompts(\"train\", demonstration, small_train_dataset, model, module_name)\n",
    "generate_dataset_activations_with_prompts(\"test\", demonstration, small_test_dataset, model, module_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these activations saved, the next step is to train a simple classifier on top of them in order to perform the sentiment classification. This is done in the `train_on_activations.ipynb` notebook."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
