{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "from typing import List, Optional\n",
    "\n",
    "import evaluate\n",
    "import kscope\n",
    "from tqdm import tqdm\n",
    "from utils import split_prompts_into_batches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "There is a bit of documentation on how to interact with the large models [here](https://kaleidoscope-sdk.readthedocs.io/en/latest/). The relevant github links to the SDK are [here](https://github.com/VectorInstitute/kaleidoscope-sdk) and underlying code [here](https://github.com/VectorInstitute/kaleidoscope)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we connect to the service through which we'll interact with the LLMs and see which models are avaiable to us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a client connection to the kscope service\n",
    "client = kscope.Client(gateway_host=\"llm.cluster.local\", gateway_port=3001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all supported models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt2',\n",
       " 'llama2-7b',\n",
       " 'llama2-7b_chat',\n",
       " 'llama2-13b',\n",
       " 'llama2-13b_chat',\n",
       " 'llama2-70b',\n",
       " 'llama2-70b_chat',\n",
       " 'falcon-7b',\n",
       " 'falcon-40b',\n",
       " 'sdxl-turbo']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all model instances that are currently active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'b56efa65-0477-43fc-9028-62f78983e86f',\n",
       "  'name': 'falcon-40b',\n",
       "  'state': 'LAUNCHING'},\n",
       " {'id': 'fa78651c-0876-4e60-b016-22998efc6377',\n",
       "  'name': 'llama2-70b',\n",
       "  'state': 'LAUNCHING'},\n",
       " {'id': 'a8675b3a-4898-438e-a772-ddc70bd1357e',\n",
       "  'name': 'llama2-7b',\n",
       "  'state': 'ACTIVE'},\n",
       " {'id': '815ca1d4-d4df-4f0b-8c00-41a0fb82a3c0',\n",
       "  'name': 'falcon-7b',\n",
       "  'state': 'ACTIVE'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.model_instances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we obtain a handle to a model. In this example, let's use the Falcon 7B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.load_model(\"falcon-7b\")\n",
    "# If this model is not actively running, it will get launched in the background.\n",
    "# In this case, wait until it moves into an \"ACTIVE\" state before proceeding.\n",
    "while model.state != \"ACTIVE\":\n",
    "    time.sleep(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to configure the model to generate in the way we want it to. So we set a number of important parameters. For a discussion of the configuration parameters see: `src/reference_implementations/prompting_vector_llms/CONFIG_README.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_generation_config = {\"max_tokens\": 75, \"top_k\": 4, \"top_p\": 1.0, \"temperature\": 0.5}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to try out some few shot and zero shot translation from French to English. We take a sample from the very large WMT14 translation dataset, specifically considering French->English translation only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_texts = []\n",
    "english_texts = []\n",
    "with open(\"resources/translation_dataset/wmt14_sample.json\") as file:\n",
    "    data = json.load(file)[\"dataset\"]\n",
    "    for french_english_pair in data:\n",
    "        french_text = french_english_pair[\"fr\"]\n",
    "        french_texts.append(french_text)\n",
    "        english_text = french_english_pair[\"en\"]\n",
    "        english_texts.append(english_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Shot Prompt Structure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our zero-shot prompt example, we'll start by using the same format as the original [GPT-3 paper](https://arxiv.org/pdf/2005.14165.pdf). That is:\n",
    "\n",
    "Q: What is the {target language} translation of {source text} A: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_zero_shot_prompt(french_text: str) -> str:\n",
    "    return f\"Q: What is the English translation of {french_text}\\nA:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_prompts = []\n",
    "for french_text in french_texts:\n",
    "    zero_shot_prompt = construct_zero_shot_prompt(french_text)\n",
    "    zero_shot_prompts.append(zero_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Prompt\n",
      "Q: What is the English translation of Reprise de la session\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "print(f\"Example Prompt\\n{zero_shot_prompts[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-Shot Prompt Structure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to speed up inference a bit, we only use 10-shot prompts for our translation task. The original [GPT-3 paper](https://arxiv.org/pdf/2005.14165.pdf), as do many others papers, uses a very large 64-shot prompt to induce their observed performance. The first prompt format that we use is distinctly different from the zero-shot setting. We borrow the GPT-3 structure of:\n",
    "\n",
    "{source text} = {target text}\\n\\n\n",
    "\n",
    "but add on an instruction at the beginning \n",
    "\n",
    "\"Translate the follow sentences from French to English.\\n\\n\"\n",
    "\n",
    "To create the demonstrations, we take the first `n_examples` from the dataset sample, and use the rest for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_few_shot_prompt_structure(french_text: str, english_text: Optional[str] = None) -> str:\n",
    "    if english_text:\n",
    "        return f\"{french_text} = {english_text}\\n\\n\"\n",
    "    else:\n",
    "        return f\"{french_text} = \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_few_shot_prompt(french_text: str, demonstrations: str) -> str:\n",
    "    return f\"{demonstrations}{construct_few_shot_prompt_structure(french_text)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 10\n",
    "demonstrations = []\n",
    "# Create the demonstrations for translation\n",
    "for french_text, english_text in zip(french_texts[0:n_examples], english_texts[0:n_examples]):\n",
    "    demonstrations.append(construct_few_shot_prompt_structure(french_text, english_text))\n",
    "\n",
    "demonstration_str = \"\".join(demonstrations)\n",
    "demonstration_str = f\"Translate the following sentences from French to English.\\n\\n{demonstration_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we're only taking the remaining 90 examples from the test set, since we used the first 10 for few-shot\n",
    "# examples\n",
    "few_shot_prompts = [\n",
    "    construct_few_shot_prompt(french_text, demonstration_str) for french_text in french_texts[n_examples:]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Prompt\n",
      "Translate the following sentences from French to English.\n",
      "\n",
      "Reprise de la session = Resumption of the session\n",
      "\n",
      "Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances. = I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      "\n",
      "Comme vous avez pu le constater, le grand \"bogue de l'an 2000\" ne s'est pas produit. En revanche, les citoyens d'un certain nombre de nos pays ont été victimes de catastrophes naturelles qui ont vraiment été terribles. = Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n",
      "\n",
      "Vous avez souhaité un débat à ce sujet dans les prochains jours, au cours de cette période de session. = You have requested a debate on this subject in the course of the next few days, during this part-session.\n",
      "\n",
      "En attendant, je souhaiterais, comme un certain nombre de collègues me l'ont demandé, que nous observions une minute de silence pour toutes les victimes, des tempêtes notamment, dans les différents pays de l'Union européenne qui ont été touchés. = In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\n",
      "\n",
      "Je vous invite à vous lever pour cette minute de silence. = Please rise, then, for this minute' s silence.\n",
      "\n",
      "(Le Parlement, debout, observe une minute de silence) = (The House rose and observed a minute' s silence)\n",
      "\n",
      "Madame la Présidente, c'est une motion de procédure. = Madam President, on a point of order.\n",
      "\n",
      "Vous avez probablement appris par la presse et par la télévision que plusieurs attentats à la bombe et crimes ont été perpétrés au Sri Lanka. = You will be aware from the press and television that there have been a number of bomb explosions and killings in Sri Lanka.\n",
      "\n",
      "L'une des personnes qui vient d'être assassinée au Sri Lanka est M. Kumar Ponnambalam, qui avait rendu visite au Parlement européen il y a quelques mois à peine. = One of the people assassinated very recently in Sri Lanka was Mr Kumar Ponnambalam, who had visited the European Parliament just a few months ago.\n",
      "\n",
      "Ne pensez-vous pas, Madame la Présidente, qu'il conviendrait d'écrire une lettre au président du Sri Lanka pour lui communiquer que le Parlement déplore les morts violentes, dont celle de M. Ponnambalam, et pour l'inviter instamment à faire tout ce qui est en son pouvoir pour chercher une réconciliation pacifique et mettre un terme à cette situation particulièrement difficile. = \n"
     ]
    }
   ],
   "source": [
    "print(f\"Example Prompt\\n{few_shot_prompts[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Some Generations\n",
    "\n",
    "Let's give each a try with some basic french sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_1 = \"J'aime mon chien.\"  # I love my dog.\n",
    "example_2 = \"Il y a des gens partout.\"  # There are people everywhere.\n",
    "example_3 = (\n",
    "    \"Jusqu'à présent, l'hiver a été étrange à Toronto.\"  # It has been an very weird winter in Toronto thus far.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_response(response: str) -> str:\n",
    "    # find the first sentence\n",
    "    sentences = re.findall(r\".*?[.!\\?]\", response)\n",
    "    first_sentence = sentences[0] if len(sentences) > 0 else response\n",
    "    # strip leading and trailing non-alpha numeric characters\n",
    "    lead_strip = re.sub(r\"^[^A-Za-z0-9 _\\.,!\\\"\\'\\?]+\", \"\", first_sentence.strip())\n",
    "    return re.sub(r\"[^A-Za-z0-9 _\\.,!\\\"\\'\\?]+$\", \"\", lead_strip)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero Shot Examples.\n",
    "\n",
    "We only grab the first sentence in the response because we are targeting translation of only one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt\n",
      "Q: What is the English translation of J'aime mon chien.\n",
      "A:\n",
      "Parsed Response\n",
      "I love my dog.\n"
     ]
    }
   ],
   "source": [
    "# Place examples in the zero shot template\n",
    "zero_shot_prompt = construct_zero_shot_prompt(example_1)\n",
    "generation = model.generate(zero_shot_prompt, long_generation_config)\n",
    "print(f\"Prompt\\n{zero_shot_prompt}\")\n",
    "# Grab the first sentence output.\n",
    "print(\"Parsed Response\")\n",
    "print(parse_model_response(generation.generation[\"sequences\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt\n",
      "Q: What is the English translation of Il y a des gens partout.\n",
      "A:\n",
      "Parsed Response\n",
      "There are people everywhere.\n"
     ]
    }
   ],
   "source": [
    "# Place examples in the zero shot template\n",
    "zero_shot_prompt = construct_zero_shot_prompt(example_2)\n",
    "generation = model.generate(zero_shot_prompt, long_generation_config)\n",
    "print(f\"Prompt\\n{zero_shot_prompt}\")\n",
    "# Grab the first sentence output.\n",
    "print(\"Parsed Response\")\n",
    "print(parse_model_response(generation.generation[\"sequences\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt\n",
      "Q: What is the English translation of Jusqu'à présent, l'hiver a été étrange à Toronto.\n",
      "A:\n",
      "Parsed Response\n",
      "Until now, winter has been strange in Toronto.\n"
     ]
    }
   ],
   "source": [
    "# Place examples in the zero shot template\n",
    "zero_shot_prompt = construct_zero_shot_prompt(example_3)\n",
    "generation = model.generate(zero_shot_prompt, long_generation_config)\n",
    "print(f\"Prompt\\n{zero_shot_prompt}\")\n",
    "# Grab the first sentence output.\n",
    "print(\"Parsed Response\")\n",
    "print(parse_model_response(generation.generation[\"sequences\"][0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In spite of not being trained explicitly on significant mulitlingual texts, zero-shot actually works pretty well for these examples.\n",
    "\n",
    "### Few-shot Examples \n",
    "\n",
    "Again, we only grab the first sentence in the response because we are targeting translation of only one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt\n",
      "Translate the following sentences from French to English.\n",
      "\n",
      "Reprise de la session = Resumption of the session\n",
      "\n",
      "Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances. = I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      "\n",
      "Comme vous avez pu le constater, le grand \"bogue de l'an 2000\" ne s'est pas produit. En revanche, les citoyens d'un certain nombre de nos pays ont été victimes de catastrophes naturelles qui ont vraiment été terribles. = Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n",
      "\n",
      "Vous avez souhaité un débat à ce sujet dans les prochains jours, au cours de cette période de session. = You have requested a debate on this subject in the course of the next few days, during this part-session.\n",
      "\n",
      "En attendant, je souhaiterais, comme un certain nombre de collègues me l'ont demandé, que nous observions une minute de silence pour toutes les victimes, des tempêtes notamment, dans les différents pays de l'Union européenne qui ont été touchés. = In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\n",
      "\n",
      "Je vous invite à vous lever pour cette minute de silence. = Please rise, then, for this minute' s silence.\n",
      "\n",
      "(Le Parlement, debout, observe une minute de silence) = (The House rose and observed a minute' s silence)\n",
      "\n",
      "Madame la Présidente, c'est une motion de procédure. = Madam President, on a point of order.\n",
      "\n",
      "Vous avez probablement appris par la presse et par la télévision que plusieurs attentats à la bombe et crimes ont été perpétrés au Sri Lanka. = You will be aware from the press and television that there have been a number of bomb explosions and killings in Sri Lanka.\n",
      "\n",
      "L'une des personnes qui vient d'être assassinée au Sri Lanka est M. Kumar Ponnambalam, qui avait rendu visite au Parlement européen il y a quelques mois à peine. = One of the people assassinated very recently in Sri Lanka was Mr Kumar Ponnambalam, who had visited the European Parliament just a few months ago.\n",
      "\n",
      "J'aime mon chien. = \n",
      "Parsed Response\n",
      "I love my dog.\n"
     ]
    }
   ],
   "source": [
    "# Place examples in the few shot template\n",
    "few_shot_prompt = construct_few_shot_prompt(example_1, demonstration_str)\n",
    "print(f\"Prompt\\n{few_shot_prompt}\")\n",
    "generation = model.generate(few_shot_prompt, long_generation_config)\n",
    "# Grab the first sentence output.\n",
    "print(\"Parsed Response\")\n",
    "print(parse_model_response(generation.generation[\"sequences\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt\n",
      "Translate the following sentences from French to English.\n",
      "\n",
      "Reprise de la session = Resumption of the session\n",
      "\n",
      "Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances. = I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      "\n",
      "Comme vous avez pu le constater, le grand \"bogue de l'an 2000\" ne s'est pas produit. En revanche, les citoyens d'un certain nombre de nos pays ont été victimes de catastrophes naturelles qui ont vraiment été terribles. = Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n",
      "\n",
      "Vous avez souhaité un débat à ce sujet dans les prochains jours, au cours de cette période de session. = You have requested a debate on this subject in the course of the next few days, during this part-session.\n",
      "\n",
      "En attendant, je souhaiterais, comme un certain nombre de collègues me l'ont demandé, que nous observions une minute de silence pour toutes les victimes, des tempêtes notamment, dans les différents pays de l'Union européenne qui ont été touchés. = In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\n",
      "\n",
      "Je vous invite à vous lever pour cette minute de silence. = Please rise, then, for this minute' s silence.\n",
      "\n",
      "(Le Parlement, debout, observe une minute de silence) = (The House rose and observed a minute' s silence)\n",
      "\n",
      "Madame la Présidente, c'est une motion de procédure. = Madam President, on a point of order.\n",
      "\n",
      "Vous avez probablement appris par la presse et par la télévision que plusieurs attentats à la bombe et crimes ont été perpétrés au Sri Lanka. = You will be aware from the press and television that there have been a number of bomb explosions and killings in Sri Lanka.\n",
      "\n",
      "L'une des personnes qui vient d'être assassinée au Sri Lanka est M. Kumar Ponnambalam, qui avait rendu visite au Parlement européen il y a quelques mois à peine. = One of the people assassinated very recently in Sri Lanka was Mr Kumar Ponnambalam, who had visited the European Parliament just a few months ago.\n",
      "\n",
      "Il y a des gens partout. = \n",
      "Parsed Response\n",
      "There are people everywhere.\n"
     ]
    }
   ],
   "source": [
    "# Place examples in the few shot template\n",
    "few_shot_prompt = construct_few_shot_prompt(example_2, demonstration_str)\n",
    "print(f\"Prompt\\n{few_shot_prompt}\")\n",
    "generation = model.generate(few_shot_prompt, long_generation_config)\n",
    "# Grab the first sentence output.\n",
    "print(\"Parsed Response\")\n",
    "print(parse_model_response(generation.generation[\"sequences\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt\n",
      "Translate the following sentences from French to English.\n",
      "\n",
      "Reprise de la session = Resumption of the session\n",
      "\n",
      "Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances. = I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      "\n",
      "Comme vous avez pu le constater, le grand \"bogue de l'an 2000\" ne s'est pas produit. En revanche, les citoyens d'un certain nombre de nos pays ont été victimes de catastrophes naturelles qui ont vraiment été terribles. = Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n",
      "\n",
      "Vous avez souhaité un débat à ce sujet dans les prochains jours, au cours de cette période de session. = You have requested a debate on this subject in the course of the next few days, during this part-session.\n",
      "\n",
      "En attendant, je souhaiterais, comme un certain nombre de collègues me l'ont demandé, que nous observions une minute de silence pour toutes les victimes, des tempêtes notamment, dans les différents pays de l'Union européenne qui ont été touchés. = In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\n",
      "\n",
      "Je vous invite à vous lever pour cette minute de silence. = Please rise, then, for this minute' s silence.\n",
      "\n",
      "(Le Parlement, debout, observe une minute de silence) = (The House rose and observed a minute' s silence)\n",
      "\n",
      "Madame la Présidente, c'est une motion de procédure. = Madam President, on a point of order.\n",
      "\n",
      "Vous avez probablement appris par la presse et par la télévision que plusieurs attentats à la bombe et crimes ont été perpétrés au Sri Lanka. = You will be aware from the press and television that there have been a number of bomb explosions and killings in Sri Lanka.\n",
      "\n",
      "L'une des personnes qui vient d'être assassinée au Sri Lanka est M. Kumar Ponnambalam, qui avait rendu visite au Parlement européen il y a quelques mois à peine. = One of the people assassinated very recently in Sri Lanka was Mr Kumar Ponnambalam, who had visited the European Parliament just a few months ago.\n",
      "\n",
      "Jusqu'à présent, l'hiver a été étrange à Toronto. = \n",
      "Parsed Response\n",
      "'Til now, winter has been strange in Toronto.\n"
     ]
    }
   ],
   "source": [
    "# Place examples in the few shot template\n",
    "few_shot_prompt = construct_few_shot_prompt(example_3, demonstration_str)\n",
    "print(f\"Prompt\\n{few_shot_prompt}\")\n",
    "generation = model.generate(few_shot_prompt, long_generation_config)\n",
    "# Grab the first sentence output.\n",
    "print(\"Parsed Response\")\n",
    "print(parse_model_response(generation.generation[\"sequences\"][0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's measure the BLEU scores for the dataset that we have sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_metric = evaluate.load(\"bleu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot results for full translation sample test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [08:34<00:00,  5.14s/it]\n"
     ]
    }
   ],
   "source": [
    "# Split prompts into batches for memory management.\n",
    "zero_shot_translations = []\n",
    "zero_shot_batches = split_prompts_into_batches(zero_shot_prompts, batch_size=1)\n",
    "for zero_shot_batch in tqdm(zero_shot_batches):\n",
    "    generations = model.generate(zero_shot_batch, long_generation_config)\n",
    "    for single_generation in generations.generation[\"sequences\"]:\n",
    "        generation_text = parse_model_response(single_generation)\n",
    "        zero_shot_translations.append(generation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_references_for_bleu(references: List[str]) -> List[List[str]]:\n",
    "    # The bleu metric requires inputs to be stored as lists of lists. So we encapsulate each reference in a list\n",
    "    return [[reference] for reference in references]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.07443099041449071,\n",
       " 'precisions': [0.30645944633317146,\n",
       "  0.13067891781521185,\n",
       "  0.07423345884884347,\n",
       "  0.046617396247868106],\n",
       " 'brevity_penalty': 0.6859970294287353,\n",
       " 'length_ratio': 0.7262786596119929,\n",
       " 'translation_length': 2059,\n",
       " 'reference_length': 2835}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.compute(predictions=zero_shot_translations, references=convert_references_for_bleu(english_texts))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot example results for full translation sample test set\n",
    "\n",
    "__NOTE__: This takes quite a while to run due to the sequence length associated with 10-shot prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [18:20<00:00, 12.23s/it]\n"
     ]
    }
   ],
   "source": [
    "# Split prompts into batches for memory management.\n",
    "few_shot_translations = []\n",
    "few_shot_batches = split_prompts_into_batches(few_shot_prompts, batch_size=1)\n",
    "for few_shot_batch in tqdm(few_shot_batches):\n",
    "    generations = model.generate(few_shot_batch, long_generation_config)\n",
    "    for single_generation in generations.generation[\"sequences\"]:\n",
    "        generation_text = parse_model_response(single_generation)\n",
    "        few_shot_translations.append(generation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.2745064853905504,\n",
       " 'precisions': [0.5810978126289723,\n",
       "  0.347621088726961,\n",
       "  0.23207126948775056,\n",
       "  0.16411682892906815],\n",
       " 'brevity_penalty': 0.9268728194309799,\n",
       " 'length_ratio': 0.9294207901802839,\n",
       " 'translation_length': 2423,\n",
       " 'reference_length': 2607}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that we're only taking the remaining 90 examples from the test set, since we used the first 10 for few-shot\n",
    "# examples\n",
    "bleu_metric.compute(\n",
    "    predictions=few_shot_translations, references=convert_references_for_bleu(english_texts[n_examples:])\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the few-shot prompt does a much better job in translation, at least as measured by the BLEU Score. Let's briefly consider why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Je ne suis pas au courant de ce que vous dites.',\n",
       " \"Je voudrais donc répéter, Madame la Présidente, que, pour notre part, nous avons discuté du programme d'action pour les cinq prochaines années et que nous sommes prêts à venir présenter le programme pour les cinq prochaines années quand le Parlement le décidera, y compris cette semaine, si telle est sa décision, et le programme pour\",\n",
       " 'I propose that we vote on the request of the Socialist Group for the Commission to adopt its strategic objectives.',\n",
       " 'The President.',\n",
       " 'I would like to make a statement on the question of the day, Wednesday, on the matter of the capital gains tax.',\n",
       " \"The English translation of Le groupe PPE-DE demande de retirer ce point de l'ordre du jour is: The Group of the European People's Party (Christian Democrats) asks to withdraw this item from the agenda.\",\n",
       " 'There is no English translation for this.',\n",
       " 'Madame la Présidente, je voudrais répondre à la question de M.',\n",
       " \"Je ne sais pas si cette information est exacte mais quoi qu'il en soit, le groupe PPE-DE vous saurait gré de supprimer ce point de l'ordre du jour car le Parlement s'est en effet maintes fois saisi de cette question.\",\n",
       " \"The English translation of Des décisions existent qui s'opposent à une telle taxe is Decisions exist that oppose such a tax.\"]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_translations[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I should add, Madam President, that, on the Commission' s side, we are ready and willing to hold this debate when you see fit, that we were ready to develop it this week, as had been decided at the outset, based on the fact that it was presented the day before in a speech to the groups in Parliament.\",\n",
       " 'Mr President, I should like to repeat, Madam President, that, for our part, we have discussed the programme for the next five years and that we are ready to come and present the programme for the next five years when the House decides to do so, including this week, if that is its decision, and the programme for the year 2000, next',\n",
       " \"I propose that we vote on the request of the Socialist Group for the reinsertion of the Commission' s statement on its strategic objectives.\",\n",
       " 'Je vous remercie.',\n",
       " 'On to the next point of order, Madam President, I have a further proposal concerning the oral question on the capital tax.',\n",
       " 'The PPE-DE Group is asking that this item be taken off the agenda.',\n",
       " 'Is there a colleague to speak on behalf of the group and justify this request?',\n",
       " \"Laughter)\\n\\nMadame la Présidente, pour répondre aux rires que j'entends parmi les socialistes, on m'a dit que de larges pans du groupe socialiste aimeraient également supprimer ce point de l'ordre du jour car lors du scrutin au sein de la Conférence des présidents, les collègues responsables du\",\n",
       " 'I do not know whether this information is correct but whatever the case may be, the PPE-DE Group would be grateful if you would remove this item from the order of business because the European Parliament has, on many occasions, taken up this question.',\n",
       " 'There are) decisions which oppose such a tax.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_translations[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by inspecting the outputs of the first few translations of the model, we can see where a portion, at least, of the disparity is coming from. The zero shot prompts often provide decent translations, but the model does not always produce an english translation immediately or at all. On the other hand, the few shot translations are all in English and of high fidelity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt_notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
