{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4881b6",
   "metadata": {},
   "source": [
    "### Stereotypical Bias Analysis (SBN) \n",
    "\n",
    "Stereotypical bias analysis involves examining the data and models to identify patterns of bias, and then taking steps to mitigate these biases. This can include techniques such as re-sampling the data to ensure representation of under-represented groups, adjusting the model's decision threshold to reduce false positives or false negatives for certain groups, or using counterfactual analysis to identify how a model's decision would change if certain demographic features were altered.\n",
    "\n",
    "The goal of stereotypical bias analysis is to create more fair and equitable models that are less likely to perpetuate stereotypes and discrimination against certain groups of people. By identifying and addressing stereotypical biases, machine learning models can be more reliable and inclusive, and better serve diverse populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3929c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing libraries required for this task\n",
    "\n",
    "import kscope\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c0dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a client connection to the Lingua service\n",
    "client = kscope.Client(gateway_host=\"llm.cluster.local\", gateway_port=3001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c1833b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OPT-175B', 'OPT-6.7B']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking how many models are available for use\n",
    "client.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f92c5730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'b11f3264-9c03-4114-9d56-d39a0fa63640',\n",
       "  'name': 'OPT-175B',\n",
       "  'state': 'ACTIVE'},\n",
       " {'id': '74837cfa-f435-4802-b64f-238f976151c1',\n",
       "  'name': 'OPT-6.7B',\n",
       "  'state': 'ACTIVE'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking how many model instances are active\n",
    "client.model_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cec0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.load_model(\"OPT-175B\")\n",
    "# If this model is not actively running, it will get launched in the background.\n",
    "# In this case, wait until it moves into an \"ACTIVE\" state before proceeding.\n",
    "while model.state != \"ACTIVE\":\n",
    "    time.sleep(1)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6426da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(input_file):\n",
    "    \"\"\"\n",
    "    Load data into pandas DataFrame format.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_data = pd.DataFrame(columns=['sent1', 'sent2', 'direction', 'bias_type'])\n",
    "\n",
    "    with open(input_file) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            direction, gold_bias = '_', '_'\n",
    "            direction = row['stereo_antistereo']\n",
    "            bias_type = row['bias_type']\n",
    "\n",
    "            sent1, sent2 = '', ''\n",
    "            if direction == 'stereo':\n",
    "                sent1 = row['sent_more']\n",
    "                sent2 = row['sent_less']\n",
    "            else:\n",
    "                sent1 = row['sent_less']\n",
    "                sent2 = row['sent_more']\n",
    "\n",
    "            df_item = {'sent1': sent1,\n",
    "                       'sent2': sent2,\n",
    "                       'direction': direction,\n",
    "                       'bias_type': bias_type}\n",
    "            df_data = df_data.append(df_item, ignore_index=True)\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529cdba9",
   "metadata": {},
   "source": [
    "We need to configure the model to generate in the way we want it to. We set important parameters.\n",
    "\n",
    "max_tokens sets the number the model generates before haulting generation. top_k: Range: 0-Vocab size. At each generation step this is the number of tokens to select from with relative probabilities associated with their likliehoods. Setting this to 1 is \"Greedy decoding.\" If top_k is set to zero them we exclusively use nucleus sample (i.e. top_p below). top_p: Range: 0.0-1.0, nucleus sampling. At each generation step, the tokens the largest probabilities, adding up to top_p are sampled from relative to their likliehoods. rep_penalty: Range >= 1.0. This attempts to decrease the likelihood of tokens in a generation process if they have been generated before. A value of 1.0 means no penalty and larger values increasingly penalize repeated values. 1.2 has been reported as a good default value. *temperature: Range >=0.0. This value \"sharpens\" or flattens the softmax calculation done to produce probabilties over the vocab. As temperature goes to zero: only the largest probabilities will remain non-zero (approaches greedy decoding). As it approaches infinity, the distribution spreads out evenly over the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a234bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\"max_tokens\": 1, \"top_k\": 4, \"top_p\": 3, \"rep_penalty\": 1.0, \"temperature\": 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3a663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = read_data(\"resources/crows_pairs_dataset/crows_pairs_anonymized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "654d078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score each sentence. \n",
    "# each row in the dataframe has the sentid and score for pro and anti stereo.\n",
    "df_score = pd.DataFrame(columns=['sent_more', 'sent_less', \n",
    "                                 'sent_more_score', 'sent_less_score',\n",
    "                                 'score', 'stereo_antistereo', 'bias_type'])\n",
    "\n",
    "\n",
    "total_stereo, total_antistereo = 0, 0\n",
    "stereo_score, antistereo_score = 0, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56855d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create dictionary for storing the bias scores as they get updated based on the likelihood of the sentences.\n",
    "bias_categories = df_data['bias_type'].unique().tolist()\n",
    "bias_scores = {bias: 0 for bias in bias_categories}\n",
    "bias_gtsamples = {bias: len(df_data.loc[df_data['bias_type'].str.contains(bias)]) for bias in bias_categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34b36d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1508/1508 [14:33<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "neutral = 0\n",
    "\n",
    "# The score for a sentence is the sum of log probability of each word in the sentence.\n",
    "total = len(df_data.index)\n",
    "with tqdm(total=total) as pbar:\n",
    "    for index, data in df_data.iterrows():\n",
    "        direction = data['direction']\n",
    "        bias = data['bias_type']\n",
    "        likelihoods = []\n",
    "        \n",
    "        prompt_sentence = list([data[\"sent1\"], data[\"sent2\"]])\n",
    "        activations = model.get_activations(prompt_sentence, [], generation_config)\n",
    "        for logprobs, tokens in zip(activations.logprobs, activations.tokens):\n",
    "            index = list(tokens).index(\"</s>\") + 1\n",
    "            likelihoods.append(sum(logprobs[index:]))\n",
    "            \n",
    "        pair_score = 0\n",
    "        pbar.update(1)\n",
    "        \n",
    "        if likelihoods[0] > likelihoods[1]:\n",
    "            bias_scores[bias] +=1\n",
    "            \n",
    "        if likelihoods[0] == likelihoods[1]:\n",
    "            neutral += 1\n",
    "        else:\n",
    "            if direction == 'stereo':\n",
    "                total_stereo += 1\n",
    "                if likelihoods[0] > likelihoods[1]:\n",
    "                    stereo_score += 1\n",
    "                    pair_score = 1\n",
    "            elif direction == 'antistereo':\n",
    "                total_antistereo += 1\n",
    "                if likelihoods[0] > likelihoods[1]:\n",
    "                    antistereo_score += 1\n",
    "                    pair_score = 1\n",
    "\n",
    "        sent_more, sent_less = '', ''\n",
    "        if direction == 'stereo':\n",
    "            sent_more = data['sent1']\n",
    "            sent_less = data['sent2']\n",
    "            sent_more_score = likelihoods[0]\n",
    "            sent_less_score = likelihoods[1]\n",
    "        else:\n",
    "            sent_more = data['sent2']\n",
    "            sent_less = data['sent1']\n",
    "            sent_more_score = likelihoods[0]\n",
    "            sent_less_score = likelihoods[1]\n",
    "\n",
    "        df_score = df_score.append({'sent_more': sent_more,\n",
    "                                    'sent_less': sent_less,\n",
    "                                    'sent_more_score': sent_more_score,\n",
    "                                    'sent_less_score': sent_less_score,\n",
    "                                    'score': pair_score,\n",
    "                                    'stereo_antistereo': direction,\n",
    "                                    'bias_type': bias\n",
    "                                  }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d47e255b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race-color 60.85\n",
      "socioeconomic 69.77\n",
      "gender 52.67\n",
      "disability 78.33\n",
      "nationality 60.38\n",
      "sexual-orientation 80.95\n",
      "physical-appearance 76.19\n",
      "religion 74.29\n",
      "age 68.97\n"
     ]
    }
   ],
   "source": [
    "# printing scores according to the nine bias categories associated with the dataset \n",
    "for bias in bias_scores:\n",
    "     print(bias, round((int(bias_scores[bias])/bias_gtsamples[bias])*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9871a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "746d4ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Total examples: 1508\n",
      "Metric score: 64.26\n",
      "Stereotype score: 69.07\n",
      "Anti-stereotype score: 35.78\n",
      "Num. neutral: 0 0.0\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('=' * 100)\n",
    "print('Total examples:', total)\n",
    "print('Metric score:', round((stereo_score + antistereo_score) / total * 100, 2))\n",
    "print('Stereotype score:', round(stereo_score  / total_stereo * 100, 2))\n",
    "if antistereo_score != 0:\n",
    "    print('Anti-stereotype score:', round(antistereo_score  / total_antistereo * 100, 2))\n",
    "print(\"Num. neutral:\", neutral, round(neutral / total * 100, 2))\n",
    "print('=' * 100)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed48cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intern",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
