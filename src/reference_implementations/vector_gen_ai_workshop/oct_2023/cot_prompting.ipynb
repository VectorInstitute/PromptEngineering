{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import kscope"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conecting to the Service\n",
    "First we connect to the Kaleidoscope service through which we'll interact with the LLMs and see which models are avaiable to us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a client connection to the kscope service\n",
    "client = kscope.Client(gateway_host=\"llm.cluster.local\", gateway_port=3001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all model instances that are currently active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '69765f91-ecc1-4d7f-a3a4-b18ed38370c4',\n",
       "  'name': 'falcon-40b',\n",
       "  'state': 'ACTIVE'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.model_instances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we obtain a handle to a model. In this example, let's use the Falcon-40B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.load_model(\"falcon-40b\")\n",
    "# If this model is not actively running, it will get launched in the background.\n",
    "# In this case, wait until it moves into an \"ACTIVE\" state before proceeding.\n",
    "while model.state != \"ACTIVE\":\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "moderate_generation_config = {\"max_tokens\": 100, \"top_k\": 1, \"top_p\": 1.0, \"temperature\": 0.8}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask the model some questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ottawa\n"
     ]
    }
   ],
   "source": [
    "generation = model.generate(\"What is the capital of Canada?\", moderate_generation_config)\n",
    "# Extract the text from the returned generation\n",
    "print(generation.generation[\"sequences\"][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by prompting Falcon-40B to solve some word problems using the Few-Shot CoT method proposed in [\"Chain-of-Thought Prompting Elicits Reasoning\n",
    "in Large Language Models\"](https://arxiv.org/pdf/2201.11903.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see what happens if we try to solve some word problems with a zero-shot prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples are left?\n"
     ]
    }
   ],
   "source": [
    "zero_shot_prompt = (\n",
    "    \"The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\"\n",
    ")\n",
    "\n",
    "print(zero_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get your free account and access expert answers to this and thousands of other questions\n"
     ]
    }
   ],
   "source": [
    "generation_example = model.generate(zero_shot_prompt, generation_config=moderate_generation_config)\n",
    "print(generation_example.generation[\"sequences\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct answer to this word problem is 9.\n",
    "\n",
    "Now let's try performing a few-shot prompt to see if that helps the model provide the correct answer in a format that we can extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
      "A: The answer is 11.\n",
      "\n",
      "Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = (\n",
    "    \"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis \"\n",
    "    \"balls does he have now?\\nA: The answer is 11.\\n\\nQ: The cafeteria had 23 apples. If they used 20 to make lunch \"\n",
    "    \"and bought 6 more, how many apples do they have?\\nA:\"\n",
    ")\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is 29.\n"
     ]
    }
   ],
   "source": [
    "generation_example = model.generate(few_shot_prompt, generation_config=moderate_generation_config)\n",
    "print(generation_example.generation[\"sequences\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try prompting the model with a few-shot CoT prompt, where we provide an example of the kind of reasoning required to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
      "A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
      "\n",
      "Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "few_shot_cot_prompt = (\n",
    "    \"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis \"\n",
    "    \"balls does he have now?\\nA: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. \"\n",
    "    \"5 + 6 = 11. The answer is 11.\\n\\nQ: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 \"\n",
    "    \"more, how many apples do they have?\\nA:\"\n",
    ")\n",
    "print(few_shot_cot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 - 20 = 3. 3 + 6 = 9. The answer is 9.\n"
     ]
    }
   ],
   "source": [
    "generation_example = model.generate(few_shot_cot_prompt, generation_config=moderate_generation_config)\n",
    "print(generation_example.generation[\"sequences\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try compare few-shot prompting with few-shot CoT for slightly different kind of problem. This example is drawn from the AQuA: Algebraic Word Problems task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers is? Answer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64\n",
      "A: The answer is (a).\n",
      "\n",
      "Q: The capacity of a tank of dimensions (8 m × 6 m × 2.5 m) is Answer Choices: (a) 120 litres (b) 1200 litres (c) 12000 litres (d) 120000 litres (e) None of these\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = (\n",
    "    \"Q: John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of \"\n",
    "    \"the numbers is? Answer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64\\nA: The answer is (a).\\n\\nQ: The capacity of \"\n",
    "    \"a tank of dimensions (8 m × 6 m × 2.5 m) is Answer Choices: (a) 120 litres (b) 1200 litres (c) 12000 litres (d) \"\n",
    "    \"120000 litres (e) None of these\\nA:\"\n",
    ")\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The answer is (b).\n",
      "\n",
      "Q: The average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers is? Answer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64\n",
      "A: The answer is (a).\n",
      "\n",
      "Q: The capacity of a tank of dimensions (8 m × 6 m ×\n"
     ]
    }
   ],
   "source": [
    "generation_example = model.generate(few_shot_prompt, generation_config=moderate_generation_config)\n",
    "print(generation_example.generation[\"sequences\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct choice for this problem is (d)\n",
    "\n",
    "Let's see if we can extract the correct answer with few-shot CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers is? Answer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64\n",
      "A: If 10 is added to each number, then the mean of the numbers also increases by 10. So the new mean would be 50. The answer is (a).\n",
      "\n",
      "Q: The capacity of a tank of dimensions (8 m × 6 m × 2.5 m) is Answer Choices: (a) 120 litres (b) 1200 litres (c) 12000 litres (d) 120000 litres (e) None of these \n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "few_shot_cot_prompt = (\n",
    "    \"Q: John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers \"\n",
    "    \"is? Answer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64\\nA: If 10 is added to each number, then the mean of the \"\n",
    "    \"numbers also increases by 10. So the new mean would be 50. The answer is (a).\\n\\nQ: The capacity of \"\n",
    "    \"a tank of dimensions (8 m × 6 m × 2.5 m) is Answer Choices: (a) 120 litres (b) 1200 litres (c) 12000 litres (d) \"\n",
    "    \"120000 litres (e) None of these \\nA:\"\n",
    ")\n",
    "print(few_shot_cot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The capacity of a tank of dimensions (8 m × 6 m × 2.5 m) is 120000 litres. The answer is (d).\n",
      "\n",
      "Q: The average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers is? Answer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "generation_example = model.generate(few_shot_cot_prompt, generation_config=moderate_generation_config)\n",
    "print(generation_example.generation[\"sequences\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be tedious and tricky to form useful and effective reasoning examples. Some research has shown that the choice of reasoning examples in CoT prompting can have a large impact on how well the model accomplishes the downstream task. So let's try a zero-shot CoT approach devised in [\"Large Language Models are Zero-Shot Reasoners\"](https://arxiv.org/pdf/2205.11916.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
      "A: The answer is 11.\n",
      "\n",
      "Q: There are 64 students trying out for the school's trivia teams. If 36 of them didn't get picked for the team and the rest were put into 4 groups, how many students would be in each group?\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = (\n",
    "    \"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis \"\n",
    "    \"balls does he have now?\\nA: The answer is 11.\\n\\nQ: There are 64 students trying out for the school's trivia \"\n",
    "    \"teams. If 36 of them didn't get picked for the team and the rest were put into 4 groups, how many students would \"\n",
    "    \"be in each group?\\nA:\"\n",
    ")\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The answer is 16.\n",
      "\n",
      "Q: There are 3 people in a room. One of them is a murderer. The other two are detectives. The murderer is lying. The detectives are telling the truth. The murderer says, \"I am lying.\" The first detective says, \"I am lying.\" The second detective says, \"I am telling the truth.\" Who is the murderer?\n",
      "A: The answer is the first detective.\n",
      "\n",
      "Q: A man is\n"
     ]
    }
   ],
   "source": [
    "generation_example = model.generate(few_shot_prompt, generation_config=moderate_generation_config)\n",
    "print(generation_example.generation[\"sequences\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct answer to this problem is 7.\n",
    "\n",
    "Perhaps we can extract the correct answer with zero-Shot CoT is split into two stages:\n",
    "1) Reasoning Generation\n",
    "2) Answer Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: There are 64 students trying out for the school's trivia teams. If 36 of them didn't get picked for the team and the rest were put into 4 groups, how many students would be in each group?\n",
      "A: Let’s think step by step.\n"
     ]
    }
   ],
   "source": [
    "reasoning_generation_prompt = (\n",
    "    \"Q: There are 64 students trying out for the school's trivia teams. If 36 of them didn't get picked for the team \"\n",
    "    \"and the rest were put into 4 groups, how many students would be in each group?\\nA: Let’s think step by step.\"\n",
    ")\n",
    "print(reasoning_generation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First, we need to find out how many students are in each group.\n",
      "We know that there are 64 students trying out for the school’s trivia teams.\n",
      "We also know that 36 of them didn’t get picked for the team.\n",
      "So, we can subtract 36 from 64 to find out how many students were picked for the team.\n",
      "64 – 36 = 28\n",
      "Now, we need to divide 28 by 4 to find\n"
     ]
    }
   ],
   "source": [
    "reasoning_generation = model.generate(\n",
    "    reasoning_generation_prompt, generation_config=moderate_generation_config\n",
    ").generation[\"sequences\"][0]\n",
    "print(reasoning_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: There are 64 students trying out for the school's trivia teams. If 36 of them didn't get picked for the team and the rest were put into 4 groups, how many students would be in each group?\n",
      "A: Let’s think step by step.\n",
      "First, we need to find out how many students are in each group.\n",
      "We know that there are 64 students trying out for the school’s trivia teams.\n",
      "We also know that 36 of them didn’t get picked for the team.\n",
      "So, we can subtract 36 from 64 to find out how many students were picked for the team.\n",
      "64 – 36 = 28\n",
      "Now, we need to divide 28 by 4 to find\n",
      "Therefore, the answer is\n"
     ]
    }
   ],
   "source": [
    "answer_extraction_prompt = f\"{reasoning_generation_prompt}{reasoning_generation}\\nTherefore, the answer is\"\n",
    "print(answer_extraction_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7.\n",
      "Q: A school has 100 students. If 60 of them are girls and the rest are boys, how many boys are there?\n",
      "A: Let’s think step by step.\n",
      "First, we need to find out how many boys are in the school.\n",
      "We know that there are 100 students in the school.\n",
      "We also know that 60 of them are girls.\n",
      "So, we can subtract 60 from 100 to find out how many\n"
     ]
    }
   ],
   "source": [
    "answer_generation = model.generate(answer_extraction_prompt, generation_config=moderate_generation_config).generation[\n",
    "    \"sequences\"\n",
    "][0]\n",
    "print(answer_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt_notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
