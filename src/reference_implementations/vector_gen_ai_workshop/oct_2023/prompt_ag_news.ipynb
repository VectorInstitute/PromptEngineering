{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "\n",
    "import kscope\n",
    "import pandas as pd\n",
    "from metrics import map_ag_news_int_labels, report_metrics\n",
    "from transformers import AutoTokenizer\n",
    "from utils import get_label_token_ids, get_label_with_highest_likelihood, split_prompts_into_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conecting to the Service"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we connect to the service through which we'll interact with the LLMs and see which models are avaiable to us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a client connection to the kscope service\n",
    "client = kscope.Client(gateway_host=\"llm.cluster.local\", gateway_port=6001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all model instances that are currently active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '75deb027-445d-4a24-8a72-2751a4f81a7b',\n",
       "  'name': 'OPT-175B',\n",
       "  'state': 'ACTIVE'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.model_instances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we obtain a handle to a model. In this example, let's use the OPT-175B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.load_model(\"OPT-175B\")\n",
    "# If this model is not actively running, it will get launched in the background.\n",
    "# In this case, wait until it moves into an \"ACTIVE\" state before proceeding.\n",
    "while model.state != \"ACTIVE\":\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "moderate_generation_config = {\"max_tokens\": 20, \"top_k\": 4, \"top_p\": 1.0, \"rep_penalty\": 1.5, \"temperature\": 0.7}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask the model some questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\nVancouver, duh.\\nThat's a city, not a country.\\nCanada is\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation = model.generate(\"What is the capital of Canada?\", moderate_generation_config)\n",
    "# Extract the text from the returned generation\n",
    "generation.generation[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nHowever, the country is far from independent now.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation = model.generate(\"When did Canada become an independent country?\", moderate_generation_config)\n",
    "# Extract the text from the returned generation\n",
    "generation.generation[\"text\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to have our model attempt to classify some news articles from the AG News Dataset. Articles have a single label 1-4\n",
    "\n",
    "1. World\n",
    "2. Sports\n",
    "3. Business\n",
    "4. Sci/Tech\n",
    "\n",
    "This is a constrained label space. We'll use the words \"World\", \"Sports\", \"Business\", and \"Technology\" as generative LM targets for each of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_markup(text: str) -> str:\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "    text = re.sub(r\"<.*?>+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def ag_news_processor(path: str) -> Tuple[List[str], List[str], List[str]]:\n",
    "    ag_news_data = pd.read_csv(path)\n",
    "    labels = ag_news_data[\"Class Index\"].tolist()\n",
    "    titles = ag_news_data[\"Title\"].apply(lambda x: remove_markup(x)).tolist()\n",
    "    descriptions = ag_news_data[\"Description\"].apply(lambda x: remove_markup(x)).tolist()\n",
    "    return labels, titles, descriptions\n",
    "\n",
    "\n",
    "int_to_label_map = {1: \"world\", 2: \"sports\", 3: \"business\", 4: \"technology\"}\n",
    "ag_news_labels, ag_news_titles, ag_news_descriptions = ag_news_processor(\n",
    "    \"ag_news_task_dataset/ag_news_datasets/ag_news_sample.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_news_labels = map_ag_news_int_labels(ag_news_labels, int_to_label_map)\n",
    "ag_news_descriptions = [description.replace(\"\\\\\", \" \").strip() for description in ag_news_descriptions]\n",
    "ag_news_titles = [title.strip() for title in ag_news_titles]\n",
    "label_words = [\"World\", \"Sports\", \"Business\", \"Technology\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_texts = [\n",
    "    f\"Title: {ag_news_title} Description: {ag_news_description}\"\n",
    "    for ag_news_title, ag_news_description in zip(ag_news_titles, ag_news_descriptions)\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by trying out a basic instruction prompt to see what the model does.\n",
    "\n",
    "Throughout, we're going to use a simple config corresponding to greedy extraction of a single token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_generation_config = {\"max_tokens\": 1, \"top_k\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate our very first prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Telecom lifts first quarter net profit 19pc Description: Telecom Corp today reported its September first quarter net profit rose 19 per cent to  $193 million. The profit bettered analysts #39; average forecasts of  $185m. To which category does this news article belong?\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"To which category does this news article belong?\"\n",
    "sample_texts = [f\"{model_input_text} {prompt_template}\" for model_input_text in model_input_texts[0:3]]\n",
    "print(sample_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *\n",
      "==================================\n",
      "\n",
      "\n",
      "==================================\n",
      "\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "generation = model.generate(sample_texts, short_generation_config)\n",
    "for text in generation.generation[\"text\"]:\n",
    "    print(text)\n",
    "    print(\"==================================\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not well...Now let's try to constrain the model a bit by including the desired labels in the instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Telecom lifts first quarter net profit 19pc Description: Telecom Corp today reported its September first quarter net profit rose 19 per cent to  $193 million. The profit bettered analysts #39; average forecasts of  $185m. From World, Sports, Business, Technology, the category is\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"From World, Sports, Business, Technology, the category is\"\n",
    "sample_texts = [f\"{model_input_text} {prompt_template}\" for model_input_text in model_input_texts[0:3]]\n",
    "print(sample_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " filed\n",
      "==================================\n",
      " yours\n",
      "==================================\n",
      " channel\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "generation = model.generate(sample_texts, short_generation_config)\n",
    "for text in generation.generation[\"text\"]:\n",
    "    print(text)\n",
    "    print(\"==================================\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model doesn't really answer in the space that we want it to. Let's try with some few-shot examples to see if that helps.\n",
    "\n",
    "__NOTE__: We have simply randomly picked the examples used in the 5-shot prompt. Different choices might be made, including 4-shot or 8-shot prompts so that categories are evenly represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Lane drives in winning run in ninth Description: Jason Lane took an unusual post-game batting practice with hitting coach Gary Gaetti after a disappointing performance Friday night. Category (World, Sports, Business, Technology): Sports \n",
      "Title: Arson attack on Jewish centre in Paris (AFP) Description: AFP - A Jewish social centre in central Paris was destroyed by fire overnight in an anti-Semitic arson attack, city authorities said. Category (World, Sports, Business, Technology): World \n",
      "Title: Oil prices look set to dominate Description: The price of oil looks set to grab headlines as analysts forecast that its record-breaking run may well continue. Category (World, Sports, Business, Technology): Business \n",
      "Title: Indexes in Japan fall short of hype Description: Japanese stocks have failed to measure up to an assessment made in April by Merrill Lynch #39;s chief global strategist, David Bowers, who said Japan was  quot;very much everyone #39;s favorite equity market. Category (World, Sports, Business, Technology): Business \n",
      "Title: UK Scientists Allowed to Clone Human Embryos (Reuters) Description: Reuters - British scientists said on Wednesday they had received permission to clone human embryos for medical research, in what they believe to be the first such license to be granted in Europe. Category (World, Sports, Business, Technology): Technology \n",
      "Title: Telecom lifts first quarter net profit 19pc Description: Telecom Corp today reported its September first quarter net profit rose 19 per cent to  $193 million. The profit bettered analysts #39; average forecasts of  $185m.Category (World, Sports, Business, Technology):\n"
     ]
    }
   ],
   "source": [
    "prompt_template_prefix = \"\"\"Title: Lane drives in winning run in ninth Description: Jason Lane took an unusual post-game batting practice with hitting coach Gary Gaetti after a disappointing performance Friday night. Category (World, Sports, Business, Technology): Sports \n",
    "Title: Arson attack on Jewish centre in Paris (AFP) Description: AFP - A Jewish social centre in central Paris was destroyed by fire overnight in an anti-Semitic arson attack, city authorities said. Category (World, Sports, Business, Technology): World \n",
    "Title: Oil prices look set to dominate Description: The price of oil looks set to grab headlines as analysts forecast that its record-breaking run may well continue. Category (World, Sports, Business, Technology): Business \n",
    "Title: Indexes in Japan fall short of hype Description: Japanese stocks have failed to measure up to an assessment made in April by Merrill Lynch #39;s chief global strategist, David Bowers, who said Japan was  quot;very much everyone #39;s favorite equity market. Category (World, Sports, Business, Technology): Business \n",
    "Title: UK Scientists Allowed to Clone Human Embryos (Reuters) Description: Reuters - British scientists said on Wednesday they had received permission to clone human embryos for medical research, in what they believe to be the first such license to be granted in Europe. Category (World, Sports, Business, Technology): Technology \n",
    "\"\"\"  # noqa\n",
    "prompt_template_postfix = \"Category (World, Sports, Business, Technology):\"\n",
    "sample_texts = [\n",
    "    f\"{prompt_template_prefix}{model_input_text}{prompt_template_postfix}\"\n",
    "    for model_input_text in model_input_texts[0:3]\n",
    "]\n",
    "print(sample_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "==================================\n",
      " Business\n",
      "==================================\n",
      " Sports\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "generation = model.generate(sample_texts, short_generation_config)\n",
    "for text in generation.generation[\"text\"]:\n",
    "    print(text)\n",
    "    print(\"==================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few-shot learning definitely helps a lot! We'll measure accuracy on a sample of the AG news dataset below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measureing Zero-shot and Few-Shot Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase_labels = [word.lower() for word in label_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Shot Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Telecom lifts first quarter net profit 19pc Description: Telecom Corp today reported its September first quarter net profit rose 19 per cent to  $193 million. The profit bettered analysts #39; average forecasts of  $185m.From World, Sports, Business, Technology, the category is\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"From World, Sports, Business, Technology, the category is\"\n",
    "prompts = [f\"{model_input_text}{prompt_template}\" for model_input_text in model_input_texts]\n",
    "print(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number 1 Complete\n",
      "Batch number 2 Complete\n",
      "Batch number 3 Complete\n",
      "Batch number 4 Complete\n",
      "Batch number 5 Complete\n",
      "Batch number 6 Complete\n",
      "Batch number 7 Complete\n",
      "Batch number 8 Complete\n",
      "Batch number 9 Complete\n",
      "Batch number 10 Complete\n",
      "Batch number 11 Complete\n",
      "Batch number 12 Complete\n",
      "Batch number 13 Complete\n",
      "Batch number 14 Complete\n",
      "Batch number 15 Complete\n",
      "Batch number 16 Complete\n",
      "Batch number 17 Complete\n",
      "Batch number 18 Complete\n",
      "Batch number 19 Complete\n",
      "Batch number 20 Complete\n",
      "Batch number 21 Complete\n",
      "Batch number 22 Complete\n",
      "Batch number 23 Complete\n",
      "Batch number 24 Complete\n",
      "Batch number 25 Complete\n",
      "Batch number 26 Complete\n",
      "Batch number 27 Complete\n",
      "Batch number 28 Complete\n",
      "Batch number 29 Complete\n",
      "Batch number 30 Complete\n",
      "Batch number 31 Complete\n",
      "Batch number 32 Complete\n",
      "Batch number 33 Complete\n",
      "Batch number 34 Complete\n",
      "Batch number 35 Complete\n",
      "Batch number 36 Complete\n",
      "Batch number 37 Complete\n",
      "Batch number 38 Complete\n",
      "Batch number 39 Complete\n",
      "Batch number 40 Complete\n",
      "Batch number 41 Complete\n",
      "Batch number 42 Complete\n",
      "Batch number 43 Complete\n",
      "Batch number 44 Complete\n",
      "Batch number 45 Complete\n",
      "Batch number 46 Complete\n",
      "Batch number 47 Complete\n",
      "Batch number 48 Complete\n",
      "Batch number 49 Complete\n",
      "Batch number 50 Complete\n",
      "Batch number 51 Complete\n",
      "Batch number 52 Complete\n",
      "Batch number 53 Complete\n",
      "Batch number 54 Complete\n",
      "Batch number 55 Complete\n",
      "Batch number 56 Complete\n",
      "Batch number 57 Complete\n",
      "Batch number 58 Complete\n",
      "Batch number 59 Complete\n",
      "Batch number 60 Complete\n",
      "Batch number 61 Complete\n",
      "Batch number 62 Complete\n",
      "Batch number 63 Complete\n",
      "Batch number 64 Complete\n",
      "Batch number 65 Complete\n",
      "Batch number 66 Complete\n",
      "Batch number 67 Complete\n",
      "Batch number 68 Complete\n",
      "Batch number 69 Complete\n",
      "Batch number 70 Complete\n",
      "Batch number 71 Complete\n",
      "Batch number 72 Complete\n",
      "Batch number 73 Complete\n",
      "Batch number 74 Complete\n",
      "Batch number 75 Complete\n",
      "Batch number 76 Complete\n",
      "Batch number 77 Complete\n",
      "Batch number 78 Complete\n",
      "Batch number 79 Complete\n",
      "Batch number 80 Complete\n",
      "Batch number 81 Complete\n",
      "Batch number 82 Complete\n",
      "Batch number 83 Complete\n",
      "Batch number 84 Complete\n",
      "Batch number 85 Complete\n",
      "Batch number 86 Complete\n",
      "Batch number 87 Complete\n",
      "Batch number 88 Complete\n",
      "Batch number 89 Complete\n",
      "Batch number 90 Complete\n",
      "Batch number 91 Complete\n",
      "Batch number 92 Complete\n",
      "Batch number 93 Complete\n",
      "Batch number 94 Complete\n",
      "Batch number 95 Complete\n",
      "Batch number 96 Complete\n",
      "Batch number 97 Complete\n",
      "Batch number 98 Complete\n",
      "Batch number 99 Complete\n",
      "Batch number 100 Complete\n",
      "A total of 95 of 100 did not match any label\n"
     ]
    }
   ],
   "source": [
    "prompt_batches = split_prompts_into_batches(prompts, batch_size=1)\n",
    "predicted_labels = []\n",
    "n_no_match = 0\n",
    "for batch_num, prompt_batch in enumerate(prompt_batches):\n",
    "    generation = model.generate(prompt_batch, short_generation_config)\n",
    "    print(f\"Batch number {batch_num+1} Complete\")\n",
    "    # We'll use tokens this time and consider just the first token\n",
    "    first_predicted_tokens = [tokens[0].strip().lower() for tokens in generation.generation[\"tokens\"]]\n",
    "    # If a token doesn't correspond to one of our labels, we'll randomly select one and count how many times that\n",
    "    # happens for reporting\n",
    "    for potential_prediction in first_predicted_tokens:\n",
    "        if potential_prediction in lowercase_labels:\n",
    "            predicted_labels.append(potential_prediction)\n",
    "        else:\n",
    "            n_no_match += 1\n",
    "            predicted_labels.append(random.choice(lowercase_labels))\n",
    "print(f\"A total of {n_no_match} of {len(predicted_labels)} did not match any label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.27\n",
      "Confusion Matrix with ordering ['world', 'sports', 'business', 'technology']\n",
      "[[ 5  5 12  6]\n",
      " [ 9  6  3  3]\n",
      " [ 4  4  8  7]\n",
      " [ 6  7  7  8]]\n",
      "========================================================\n",
      "Label: world, F1: 0.1923076923076923, Recall: 0.17857142857142858, Precision: 0.20833333333333334\n",
      "Label: sports, F1: 0.2790697674418604, Recall: 0.2857142857142857, Precision: 0.2727272727272727\n",
      "Label: business, F1: 0.30188679245283023, Recall: 0.34782608695652173, Precision: 0.26666666666666666\n",
      "Label: technology, F1: 0.30769230769230765, Recall: 0.2857142857142857, Precision: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "report_metrics(predicted_labels, ag_news_labels, labels_order=[\"world\", \"sports\", \"business\", \"technology\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot Accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In this example, we'll use a 5-shot prompt, as we did above and perform a \"exact match\" with our label space. That is, we parse out the first token that the model produces in its generation and simply try to string match it to one of our four label strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Lane drives in winning run in ninth Description: Jason Lane took an unusual post-game batting practice with hitting coach Gary Gaetti after a disappointing performance Friday night. Category (World, Sports, Business, Technology): Sports \n",
      "Title: Arson attack on Jewish centre in Paris (AFP) Description: AFP - A Jewish social centre in central Paris was destroyed by fire overnight in an anti-Semitic arson attack, city authorities said. Category (World, Sports, Business, Technology): World \n",
      "Title: Oil prices look set to dominate Description: The price of oil looks set to grab headlines as analysts forecast that its record-breaking run may well continue. Category (World, Sports, Business, Technology): Business \n",
      "Title: Indexes in Japan fall short of hype Description: Japanese stocks have failed to measure up to an assessment made in April by Merrill Lynch #39;s chief global strategist, David Bowers, who said Japan was  quot;very much everyone #39;s favorite equity market. Category (World, Sports, Business, Technology): Business \n",
      "Title: UK Scientists Allowed to Clone Human Embryos (Reuters) Description: Reuters - British scientists said on Wednesday they had received permission to clone human embryos for medical research, in what they believe to be the first such license to be granted in Europe. Category (World, Sports, Business, Technology): Technology \n",
      "Title: Telecom lifts first quarter net profit 19pc Description: Telecom Corp today reported its September first quarter net profit rose 19 per cent to  $193 million. The profit bettered analysts #39; average forecasts of  $185m.Category (World, Sports, Business, Technology):\n"
     ]
    }
   ],
   "source": [
    "prompt_template_prefix = \"\"\"Title: Lane drives in winning run in ninth Description: Jason Lane took an unusual post-game batting practice with hitting coach Gary Gaetti after a disappointing performance Friday night. Category (World, Sports, Business, Technology): Sports \n",
    "Title: Arson attack on Jewish centre in Paris (AFP) Description: AFP - A Jewish social centre in central Paris was destroyed by fire overnight in an anti-Semitic arson attack, city authorities said. Category (World, Sports, Business, Technology): World \n",
    "Title: Oil prices look set to dominate Description: The price of oil looks set to grab headlines as analysts forecast that its record-breaking run may well continue. Category (World, Sports, Business, Technology): Business \n",
    "Title: Indexes in Japan fall short of hype Description: Japanese stocks have failed to measure up to an assessment made in April by Merrill Lynch #39;s chief global strategist, David Bowers, who said Japan was  quot;very much everyone #39;s favorite equity market. Category (World, Sports, Business, Technology): Business \n",
    "Title: UK Scientists Allowed to Clone Human Embryos (Reuters) Description: Reuters - British scientists said on Wednesday they had received permission to clone human embryos for medical research, in what they believe to be the first such license to be granted in Europe. Category (World, Sports, Business, Technology): Technology \n",
    "\"\"\"  # noqa\n",
    "prompt_template_postfix = \"Category (World, Sports, Business, Technology):\"\n",
    "prompts = [\n",
    "    f\"{prompt_template_prefix}{model_input_text}{prompt_template_postfix}\" for model_input_text in model_input_texts\n",
    "]\n",
    "print(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number 1 Complete\n",
      "Batch number 2 Complete\n",
      "Batch number 3 Complete\n",
      "Batch number 4 Complete\n",
      "Batch number 5 Complete\n",
      "Batch number 6 Complete\n",
      "Batch number 7 Complete\n",
      "Batch number 8 Complete\n",
      "Batch number 9 Complete\n",
      "Batch number 10 Complete\n",
      "Batch number 11 Complete\n",
      "Batch number 12 Complete\n",
      "Batch number 13 Complete\n",
      "Batch number 14 Complete\n",
      "Batch number 15 Complete\n",
      "Batch number 16 Complete\n",
      "Batch number 17 Complete\n",
      "Batch number 18 Complete\n",
      "Batch number 19 Complete\n",
      "Batch number 20 Complete\n",
      "Batch number 21 Complete\n",
      "Batch number 22 Complete\n",
      "Batch number 23 Complete\n",
      "Batch number 24 Complete\n",
      "Batch number 25 Complete\n",
      "Batch number 26 Complete\n",
      "Batch number 27 Complete\n",
      "Batch number 28 Complete\n",
      "Batch number 29 Complete\n",
      "Batch number 30 Complete\n",
      "Batch number 31 Complete\n",
      "Batch number 32 Complete\n",
      "Batch number 33 Complete\n",
      "Batch number 34 Complete\n",
      "Batch number 35 Complete\n",
      "Batch number 36 Complete\n",
      "Batch number 37 Complete\n",
      "Batch number 38 Complete\n",
      "Batch number 39 Complete\n",
      "Batch number 40 Complete\n",
      "Batch number 41 Complete\n",
      "Batch number 42 Complete\n",
      "Batch number 43 Complete\n",
      "Batch number 44 Complete\n",
      "Batch number 45 Complete\n",
      "Batch number 46 Complete\n",
      "Batch number 47 Complete\n",
      "Batch number 48 Complete\n",
      "Batch number 49 Complete\n",
      "Batch number 50 Complete\n",
      "Batch number 51 Complete\n",
      "Batch number 52 Complete\n",
      "Batch number 53 Complete\n",
      "Batch number 54 Complete\n",
      "Batch number 55 Complete\n",
      "Batch number 56 Complete\n",
      "Batch number 57 Complete\n",
      "Batch number 58 Complete\n",
      "Batch number 59 Complete\n",
      "Batch number 60 Complete\n",
      "Batch number 61 Complete\n",
      "Batch number 62 Complete\n",
      "Batch number 63 Complete\n",
      "Batch number 64 Complete\n",
      "Batch number 65 Complete\n",
      "Batch number 66 Complete\n",
      "Batch number 67 Complete\n",
      "Batch number 68 Complete\n",
      "Batch number 69 Complete\n",
      "Batch number 70 Complete\n",
      "Batch number 71 Complete\n",
      "Batch number 72 Complete\n",
      "Batch number 73 Complete\n",
      "Batch number 74 Complete\n",
      "Batch number 75 Complete\n",
      "Batch number 76 Complete\n",
      "Batch number 77 Complete\n",
      "Batch number 78 Complete\n",
      "Batch number 79 Complete\n",
      "Batch number 80 Complete\n",
      "Batch number 81 Complete\n",
      "Batch number 82 Complete\n",
      "Batch number 83 Complete\n",
      "Batch number 84 Complete\n",
      "Batch number 85 Complete\n",
      "Batch number 86 Complete\n",
      "Batch number 87 Complete\n",
      "Batch number 88 Complete\n",
      "Batch number 89 Complete\n",
      "Batch number 90 Complete\n",
      "Batch number 91 Complete\n",
      "Batch number 92 Complete\n",
      "Batch number 93 Complete\n",
      "Batch number 94 Complete\n",
      "Batch number 95 Complete\n",
      "Batch number 96 Complete\n",
      "Batch number 97 Complete\n",
      "Batch number 98 Complete\n",
      "Batch number 99 Complete\n",
      "Batch number 100 Complete\n",
      "A total of 5 of 100 did not match any label\n"
     ]
    }
   ],
   "source": [
    "prompt_batches = split_prompts_into_batches(prompts, batch_size=1)\n",
    "predicted_labels = []\n",
    "n_no_match = 0\n",
    "for batch_num, prompt_batch in enumerate(prompt_batches):\n",
    "    generation = model.generate(prompt_batch, short_generation_config)\n",
    "    print(f\"Batch number {batch_num+1} Complete\")\n",
    "    # We'll use tokens this time and consider just the first token\n",
    "    first_predicted_tokens = [tokens[0].strip().lower() for tokens in generation.generation[\"tokens\"]]\n",
    "    # If a token doesn't correspond to one of our labels, we'll randomly select one and count how many times that\n",
    "    # happens for reporting\n",
    "    for potential_prediction in first_predicted_tokens:\n",
    "        if potential_prediction in lowercase_labels:\n",
    "            predicted_labels.append(potential_prediction)\n",
    "        else:\n",
    "            n_no_match += 1\n",
    "            predicted_labels.append(random.choice(lowercase_labels))\n",
    "print(f\"A total of {n_no_match} of {len(predicted_labels)} did not match any label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.61\n",
      "Confusion Matrix with ordering ['world', 'sports', 'business', 'technology']\n",
      "[[11  2 12  3]\n",
      " [ 0 18  3  0]\n",
      " [ 2  0 16  5]\n",
      " [ 1  0 11 16]]\n",
      "========================================================\n",
      "Label: world, F1: 0.5238095238095237, Recall: 0.39285714285714285, Precision: 0.7857142857142857\n",
      "Label: sports, F1: 0.8780487804878048, Recall: 0.8571428571428571, Precision: 0.9\n",
      "Label: business, F1: 0.4923076923076923, Recall: 0.6956521739130435, Precision: 0.38095238095238093\n",
      "Label: technology, F1: 0.6153846153846153, Recall: 0.5714285714285714, Precision: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "report_metrics(predicted_labels, ag_news_labels, labels_order=[\"world\", \"sports\", \"business\", \"technology\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction By Label Likelihood Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is nothing stoping the model from not selecting our labels. So can we do better? We can work around this by understanding the likelihood of our labels from the models perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'decoder.output_projection'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We're interested in the activations from the last layer of the model, because this will allow us to calculate the\n",
    "# likelihoods\n",
    "last_layer_name = model.module_names[-1]\n",
    "last_layer_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last layer of the model corresponds to the probabilities of each token in the model vocabulary. That is, it is the conditional probability\n",
    "$$\n",
    "P(y_t \\vert y_{<t}, x),\n",
    "$$\n",
    "The probability distribution over the vocabulary of the next token given the preceding tokens $y_{<t}$, and the prompt text $x$. Thus, for each token $y_{t}$ in our input, we get back a 50K vector corresponding to the probabilities over the vocabulary of $y_{t+1}$. We only care about the last token in our input, as it houses the probability of the, as yet, unseen token the model will generate.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to instantiate a tokenizer to obtain appropriate token indices for our labels. \n",
    "\n",
    "__NOTE__: All OPT models, regardless of size, used the same tokenizer. However, if you want to use a different type of model, a different tokenizer may be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' World Sports Business Technology'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "label_token_ids = get_label_token_ids(tokenizer, prompt_template, label_words)\n",
    "# If you ever need to move back from token ids, you can use tokenizer.decode or tokenizer.batch_decode\n",
    "tokenizer.decode(label_token_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the token ids of our labels to exact the probabilties from the vocabulary of the model. The token id corresponds to the index of the token in the vocabulary matrix of the underlying model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how we can extract the likelihoods given the label tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_prompted_input = f\"{model_input_texts[0]} {prompt_template}\"\n",
    "# Create a prompt with one of the label words as a completion\n",
    "activations = model.get_activations(single_prompted_input, [last_layer_name], short_generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations matrix shape: torch.Size([60, 50272])\n",
      "Predicted Label: business\n"
     ]
    }
   ],
   "source": [
    "last_layer_matrix = activations.activations[0][last_layer_name]\n",
    "# The shape of this tensor should be number of input tokens by the vocabulary size (n x 50272)\n",
    "print(f\"Activations matrix shape: {last_layer_matrix.shape}\")\n",
    "predicted_label = get_label_with_highest_likelihood(\n",
    "    last_layer_matrix, label_token_ids, int_to_label_map, right_shift=True\n",
    ")\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "Time to compare our results across three methods. \n",
    "1. Measure the accuracy of our likelihood approach without few-shot (i.e. zero-shot).\n",
    "2. Measure the accuracy of our likelihood approach with few-shot."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood Zero-shot\n",
    "\n",
    "In this example, we do not incorporate any demonstrations into the prompt (zero-shot prompt). From our experience above, the model does not do a good job generating responses that correspond to our label space. So rather than trying to match responses to our labels as strings, we extract the probabilties of our labels (see example above), as estimated by the model's verbalizer, and select the label with the highest probability as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Telecom lifts first quarter net profit 19pc Description: Telecom Corp today reported its September first quarter net profit rose 19 per cent to  $193 million. The profit bettered analysts #39; average forecasts of  $185m.From World, Sports, Business, Technology, the category is\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"From World, Sports, Business, Technology, the category is\"\n",
    "prompts = [f\"{model_input_text}{prompt_template}\" for model_input_text in model_input_texts]\n",
    "print(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number 1 Complete\n",
      "Batch number 2 Complete\n",
      "Batch number 3 Complete\n",
      "Batch number 4 Complete\n",
      "Batch number 5 Complete\n",
      "Batch number 6 Complete\n",
      "Batch number 7 Complete\n",
      "Batch number 8 Complete\n",
      "Batch number 9 Complete\n",
      "Batch number 10 Complete\n",
      "Batch number 11 Complete\n",
      "Batch number 12 Complete\n",
      "Batch number 13 Complete\n",
      "Batch number 14 Complete\n",
      "Batch number 15 Complete\n",
      "Batch number 16 Complete\n",
      "Batch number 17 Complete\n",
      "Batch number 18 Complete\n",
      "Batch number 19 Complete\n",
      "Batch number 20 Complete\n",
      "Batch number 21 Complete\n",
      "Batch number 22 Complete\n",
      "Batch number 23 Complete\n",
      "Batch number 24 Complete\n",
      "Batch number 25 Complete\n",
      "Batch number 26 Complete\n",
      "Batch number 27 Complete\n",
      "Batch number 28 Complete\n",
      "Batch number 29 Complete\n",
      "Batch number 30 Complete\n",
      "Batch number 31 Complete\n",
      "Batch number 32 Complete\n",
      "Batch number 33 Complete\n",
      "Batch number 34 Complete\n",
      "Batch number 35 Complete\n",
      "Batch number 36 Complete\n",
      "Batch number 37 Complete\n",
      "Batch number 38 Complete\n",
      "Batch number 39 Complete\n",
      "Batch number 40 Complete\n",
      "Batch number 41 Complete\n",
      "Batch number 42 Complete\n",
      "Batch number 43 Complete\n",
      "Batch number 44 Complete\n",
      "Batch number 45 Complete\n",
      "Batch number 46 Complete\n",
      "Batch number 47 Complete\n",
      "Batch number 48 Complete\n",
      "Batch number 49 Complete\n",
      "Batch number 50 Complete\n",
      "Batch number 51 Complete\n",
      "Batch number 52 Complete\n",
      "Batch number 53 Complete\n",
      "Batch number 54 Complete\n",
      "Batch number 55 Complete\n",
      "Batch number 56 Complete\n",
      "Batch number 57 Complete\n",
      "Batch number 58 Complete\n",
      "Batch number 59 Complete\n",
      "Batch number 60 Complete\n",
      "Batch number 61 Complete\n",
      "Batch number 62 Complete\n",
      "Batch number 63 Complete\n",
      "Batch number 64 Complete\n",
      "Batch number 65 Complete\n",
      "Batch number 66 Complete\n",
      "Batch number 67 Complete\n",
      "Batch number 68 Complete\n",
      "Batch number 69 Complete\n",
      "Batch number 70 Complete\n",
      "Batch number 71 Complete\n",
      "Batch number 72 Complete\n",
      "Batch number 73 Complete\n",
      "Batch number 74 Complete\n",
      "Batch number 75 Complete\n",
      "Batch number 76 Complete\n",
      "Batch number 77 Complete\n",
      "Batch number 78 Complete\n",
      "Batch number 79 Complete\n",
      "Batch number 80 Complete\n",
      "Batch number 81 Complete\n",
      "Batch number 82 Complete\n",
      "Batch number 83 Complete\n",
      "Batch number 84 Complete\n",
      "Batch number 85 Complete\n",
      "Batch number 86 Complete\n",
      "Batch number 87 Complete\n",
      "Batch number 88 Complete\n",
      "Batch number 89 Complete\n",
      "Batch number 90 Complete\n",
      "Batch number 91 Complete\n",
      "Batch number 92 Complete\n",
      "Batch number 93 Complete\n",
      "Batch number 94 Complete\n",
      "Batch number 95 Complete\n",
      "Batch number 96 Complete\n",
      "Batch number 97 Complete\n",
      "Batch number 98 Complete\n",
      "Batch number 99 Complete\n",
      "Batch number 100 Complete\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = []\n",
    "prompt_batches = split_prompts_into_batches(prompts, batch_size=1)\n",
    "for batch_num, prompt_batch in enumerate(prompt_batches):\n",
    "    activations = model.get_activations(prompt_batch, [last_layer_name], short_generation_config)\n",
    "    print(f\"Batch number {batch_num+1} Complete\")\n",
    "    for activations_single_prompt in activations.activations:\n",
    "        last_layer_matrix = activations_single_prompt[last_layer_name]\n",
    "        predicted_label = get_label_with_highest_likelihood(\n",
    "            last_layer_matrix, label_token_ids, int_to_label_map, right_shift=True\n",
    "        )\n",
    "        predicted_labels.append(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.44\n",
      "Confusion Matrix with ordering ['world', 'sports', 'business', 'technology']\n",
      "[[25  1  2  0]\n",
      " [15  2  4  0]\n",
      " [ 7  0 16  0]\n",
      " [12  0 15  1]]\n",
      "========================================================\n",
      "Label: world, F1: 0.5747126436781609, Recall: 0.8928571428571429, Precision: 0.423728813559322\n",
      "Label: sports, F1: 0.16666666666666666, Recall: 0.09523809523809523, Precision: 0.6666666666666666\n",
      "Label: business, F1: 0.5333333333333333, Recall: 0.6956521739130435, Precision: 0.43243243243243246\n",
      "Label: technology, F1: 0.0689655172413793, Recall: 0.03571428571428571, Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "report_metrics(predicted_labels, ag_news_labels, labels_order=[\"world\", \"sports\", \"business\", \"technology\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood with Few-Shot\n",
    "\n",
    "The zero-shot prompt combined with likelihood estimation for our label space doesn't do a great job, but it is a lot better than when we tried to exact match the generation. Let's combine the two approaches. We'll use a 5-shot prompt, as we did in the exact match example above, but now we'll use likelihood over our labels as the prediction mechanism rather than exact matching the first generated token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Lane drives in winning run in ninth Description: Jason Lane took an unusual post-game batting practice with hitting coach Gary Gaetti after a disappointing performance Friday night. Category (World, Sports, Business, Technology): Sports \n",
      "Title: Arson attack on Jewish centre in Paris (AFP) Description: AFP - A Jewish social centre in central Paris was destroyed by fire overnight in an anti-Semitic arson attack, city authorities said. Category (World, Sports, Business, Technology): World \n",
      "Title: Oil prices look set to dominate Description: The price of oil looks set to grab headlines as analysts forecast that its record-breaking run may well continue. Category (World, Sports, Business, Technology): Business \n",
      "Title: Indexes in Japan fall short of hype Description: Japanese stocks have failed to measure up to an assessment made in April by Merrill Lynch #39;s chief global strategist, David Bowers, who said Japan was  quot;very much everyone #39;s favorite equity market. Category (World, Sports, Business, Technology): Business \n",
      "Title: UK Scientists Allowed to Clone Human Embryos (Reuters) Description: Reuters - British scientists said on Wednesday they had received permission to clone human embryos for medical research, in what they believe to be the first such license to be granted in Europe. Category (World, Sports, Business, Technology): Technology \n",
      "Title: Telecom lifts first quarter net profit 19pc Description: Telecom Corp today reported its September first quarter net profit rose 19 per cent to  $193 million. The profit bettered analysts #39; average forecasts of  $185m.Category (World, Sports, Business, Technology):\n"
     ]
    }
   ],
   "source": [
    "prompt_template_prefix = \"\"\"Title: Lane drives in winning run in ninth Description: Jason Lane took an unusual post-game batting practice with hitting coach Gary Gaetti after a disappointing performance Friday night. Category (World, Sports, Business, Technology): Sports \n",
    "Title: Arson attack on Jewish centre in Paris (AFP) Description: AFP - A Jewish social centre in central Paris was destroyed by fire overnight in an anti-Semitic arson attack, city authorities said. Category (World, Sports, Business, Technology): World \n",
    "Title: Oil prices look set to dominate Description: The price of oil looks set to grab headlines as analysts forecast that its record-breaking run may well continue. Category (World, Sports, Business, Technology): Business \n",
    "Title: Indexes in Japan fall short of hype Description: Japanese stocks have failed to measure up to an assessment made in April by Merrill Lynch #39;s chief global strategist, David Bowers, who said Japan was  quot;very much everyone #39;s favorite equity market. Category (World, Sports, Business, Technology): Business \n",
    "Title: UK Scientists Allowed to Clone Human Embryos (Reuters) Description: Reuters - British scientists said on Wednesday they had received permission to clone human embryos for medical research, in what they believe to be the first such license to be granted in Europe. Category (World, Sports, Business, Technology): Technology \n",
    "\"\"\"  # noqa\n",
    "prompt_template_postfix = \"Category (World, Sports, Business, Technology):\"\n",
    "prompts = [\n",
    "    f\"{prompt_template_prefix}{model_input_text}{prompt_template_postfix}\" for model_input_text in model_input_texts\n",
    "]\n",
    "print(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number 1 Complete\n",
      "Batch number 2 Complete\n",
      "Batch number 3 Complete\n",
      "Batch number 4 Complete\n",
      "Batch number 5 Complete\n",
      "Batch number 6 Complete\n",
      "Batch number 7 Complete\n",
      "Batch number 8 Complete\n",
      "Batch number 9 Complete\n",
      "Batch number 10 Complete\n",
      "Batch number 11 Complete\n",
      "Batch number 12 Complete\n",
      "Batch number 13 Complete\n",
      "Batch number 14 Complete\n",
      "Batch number 15 Complete\n",
      "Batch number 16 Complete\n",
      "Batch number 17 Complete\n",
      "Batch number 18 Complete\n",
      "Batch number 19 Complete\n",
      "Batch number 20 Complete\n",
      "Batch number 21 Complete\n",
      "Batch number 22 Complete\n",
      "Batch number 23 Complete\n",
      "Batch number 24 Complete\n",
      "Batch number 25 Complete\n",
      "Batch number 26 Complete\n",
      "Batch number 27 Complete\n",
      "Batch number 28 Complete\n",
      "Batch number 29 Complete\n",
      "Batch number 30 Complete\n",
      "Batch number 31 Complete\n",
      "Batch number 32 Complete\n",
      "Batch number 33 Complete\n",
      "Batch number 34 Complete\n",
      "Batch number 35 Complete\n",
      "Batch number 36 Complete\n",
      "Batch number 37 Complete\n",
      "Batch number 38 Complete\n",
      "Batch number 39 Complete\n",
      "Batch number 40 Complete\n",
      "Batch number 41 Complete\n",
      "Batch number 42 Complete\n",
      "Batch number 43 Complete\n",
      "Batch number 44 Complete\n",
      "Batch number 45 Complete\n",
      "Batch number 46 Complete\n",
      "Batch number 47 Complete\n",
      "Batch number 48 Complete\n",
      "Batch number 49 Complete\n",
      "Batch number 50 Complete\n",
      "Batch number 51 Complete\n",
      "Batch number 52 Complete\n",
      "Batch number 53 Complete\n",
      "Batch number 54 Complete\n",
      "Batch number 55 Complete\n",
      "Batch number 56 Complete\n",
      "Batch number 57 Complete\n",
      "Batch number 58 Complete\n",
      "Batch number 59 Complete\n",
      "Batch number 60 Complete\n",
      "Batch number 61 Complete\n",
      "Batch number 62 Complete\n",
      "Batch number 63 Complete\n",
      "Batch number 64 Complete\n",
      "Batch number 65 Complete\n",
      "Batch number 66 Complete\n",
      "Batch number 67 Complete\n",
      "Batch number 68 Complete\n",
      "Batch number 69 Complete\n",
      "Batch number 70 Complete\n",
      "Batch number 71 Complete\n",
      "Batch number 72 Complete\n",
      "Batch number 73 Complete\n",
      "Batch number 74 Complete\n",
      "Batch number 75 Complete\n",
      "Batch number 76 Complete\n",
      "Batch number 77 Complete\n",
      "Batch number 78 Complete\n",
      "Batch number 79 Complete\n",
      "Batch number 80 Complete\n",
      "Batch number 81 Complete\n",
      "Batch number 82 Complete\n",
      "Batch number 83 Complete\n",
      "Batch number 84 Complete\n",
      "Batch number 85 Complete\n",
      "Batch number 86 Complete\n",
      "Batch number 87 Complete\n",
      "Batch number 88 Complete\n",
      "Batch number 89 Complete\n",
      "Batch number 90 Complete\n",
      "Batch number 91 Complete\n",
      "Batch number 92 Complete\n",
      "Batch number 93 Complete\n",
      "Batch number 94 Complete\n",
      "Batch number 95 Complete\n",
      "Batch number 96 Complete\n",
      "Batch number 97 Complete\n",
      "Batch number 98 Complete\n",
      "Batch number 99 Complete\n",
      "Batch number 100 Complete\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = []\n",
    "prompt_batches = split_prompts_into_batches(prompts, batch_size=1)\n",
    "for batch_num, prompt_batch in enumerate(prompt_batches):\n",
    "    activations = model.get_activations(prompt_batch, [last_layer_name], short_generation_config)\n",
    "    print(f\"Batch number {batch_num+1} Complete\")\n",
    "    for activations_single_prompt in activations.activations:\n",
    "        last_layer_matrix = activations_single_prompt[last_layer_name]\n",
    "        predicted_label = get_label_with_highest_likelihood(\n",
    "            last_layer_matrix, label_token_ids, int_to_label_map, right_shift=True\n",
    "        )\n",
    "        predicted_labels.append(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.74\n",
      "Confusion Matrix with ordering ['world', 'sports', 'business', 'technology']\n",
      "[[15  1  9  3]\n",
      " [ 0 20  1  0]\n",
      " [ 0  0 22  1]\n",
      " [ 0  0 11 17]]\n",
      "========================================================\n",
      "Label: world, F1: 0.6976744186046512, Recall: 0.5357142857142857, Precision: 1.0\n",
      "Label: sports, F1: 0.9523809523809523, Recall: 0.9523809523809523, Precision: 0.9523809523809523\n",
      "Label: business, F1: 0.6666666666666667, Recall: 0.9565217391304348, Precision: 0.5116279069767442\n",
      "Label: technology, F1: 0.6938775510204083, Recall: 0.6071428571428571, Precision: 0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "report_metrics(predicted_labels, ag_news_labels, labels_order=[\"world\", \"sports\", \"business\", \"technology\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt_notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
