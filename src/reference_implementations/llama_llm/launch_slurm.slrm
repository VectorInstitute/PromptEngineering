#!/bin/bash
#SBATCH --job-name=prompt_llama
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --gres=gpu:4
#SBATCH --cpus-per-task=32
#SBATCH --mem=0
#SBATCH --partition=a40
#SBATCH --qos=llm
#SBATCH --output=prompt_llama_job_%x_%j.out
#SBATCH --error=prompt_llama_job_%x_%j.err

# Exit if any line fails
set -e

echo "###############################"
echo "######## SBATCH SCRIPT ########"
echo "###############################"

# Setup dirs
TARGET_FOLDER=$1
ROOT_DIR=$(pwd)
ROOT_DIR="/ssd005/projects/llm/llama"
LOG_DIR="${ROOT_DIR}/logs"
ENV_DIR="${ROOT_DIR}/llama_env"

# Set location of host and access port
NODES=( $( scontrol show hostnames ${SLURM_JOB_NODELIST} ) )
NODES_ARRAY=(${NODES})
HEAD_NODE=${NODES_ARRAY[0]}
HEAD_NODE_IP=$(srun --nodes=1 --ntasks=1 -w "${HEAD_NODE}" hostname --ip-address)

# Redirected stdout + stderror filepaths
OUTFILE="${LOG_DIR}/output-%j-%t.out"

# Script to run with args
WORKER_SETUP_SCRIPT="${ROOT_DIR}/worker_script.sh"
PORT=42069
MODEL_SIZE="30B"

## `torchrun` args
NNODES=1
WORKERS_PER_NODE=4
RDVZ_ID=6969
RDVZ_BACKEND="c10d"
RDVZ_ENDPOINT="${HEAD_NODE_IP}:${PORT}"

## Python script args
PYTHON_SCRIPT="${ROOT_DIR}/llama/llama/example.py"
MAX_BATCH_SIZE=8
MAX_SEQ_LEN=256
CKPT_DIR="${TARGET_FOLDER}/${MODEL_SIZE}"
TOKENIZER_PATH="${TARGET_FOLDER}/tokenizer.model"

# Set env variables
export LOGLEVEL=INFO
export NCCL_IB_DISABLE=1
export NCCL_DEBUG=INFO

# Print environment and other variables
echo "SLURM_JOB_NUM_NODES=${SLURM_JOB_NUM_NODES}"
echo "HEAD_NODE=${HEAD_NODE}"
echo "HEAD_NODE_IP=${HEAD_NODE_IP}"
echo "OUTFILE=${OUTFILE}"
echo "WORKER_SETUP_SCRIPT=${WORKER_SETUP_SCRIPT}"
echo "MODEL_SIZE=${MODEL_SIZE}"
echo "TARGET_FOLDER=${TARGET_FOLDER}"
echo "NNODES=${NNODES}"
echo "WORKERS_PER_NODE=${WORKERS_PER_NODE}"
echo "RDVZ_ID=${RDVZ_ID}"
echo "RDVZ_BACKEND=${RDVZ_BACKEND}"
echo "RDVZ_ENDPOINT=${RDVZ_ENDPOINT}"
echo "PYTHON_SCRIPT=${PYTHON_SCRIPT}"
echo "MAX_BATCH_SIZE=${MAX_BATCH_SIZE}"
echo "MAX_SEQ_LEN=${MAX_SEQ_LEN}"
echo "CKPT_DIR=${CKPT_DIR}"
echo "TOKENIZER_PATH=${TOKENIZER_PATH}"

read -r -d '' cmd << EOF
bash ${WORKER_SETUP_SCRIPT} \
${HEAD_NODE_IP} \
${TARGET_FOLDER} \
${WORKERS_PER_NODE} \
${MODEL_SIZE} \
${ENV_DIR}
EOF

echo "Running command:"
echo "${cmd}"

/opt/slurm/bin/srun -N "${SLURM_JOB_NUM_NODES}" -l -o "${OUTFILE}" -e "${OUTFILE}" bash -c "${cmd}"
